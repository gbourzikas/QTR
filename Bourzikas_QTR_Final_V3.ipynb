{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Bourzikas - QTR - Final",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "https://github.com/gbourzikas/QTR/blob/main/Bourzikas_QTR_Final_V3.ipynb",
      "authorship_tag": "ABX9TyM5Jzsi0CrCsRezwr/4Yl7O",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gbourzikas/QTR/blob/main/Bourzikas_QTR_Final_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gf5ueaheyebP"
      },
      "source": [
        "# Quantifying the World - Fall 2021\n",
        "## Case Study 5 | Firewall Rule Data\n",
        "## Grant Bourzikas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stm4RxuVyjwh"
      },
      "source": [
        "## Abstract\n",
        "The problem that has been brought to our data science team comes from cybersecurity community.  The data was collected from large organization, and they want to automate the creation of firewall rulesets. To classify the firewall rules, we will determine if they should be allowed, denied, dropped, or reset thus speeding up business and decreasing complexity in their environment\n",
        "\n",
        "After reviewing the results of the algorithms, the clear winner was the SVC algorithm with 99.8.% accuracy because it did not introduce any risk to the organization and only had 28 false negatives.  While the model did take more time to run, the accuracy and protection of the organization was Top Notch. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6vKp5rfym3l"
      },
      "source": [
        "# Introduction\n",
        "The problem that has been brought to our data science team comes from cybersecurity community.  The data was collected from large organization, and they want to automate the creation of firewall rulesets. To classify the firewall rules, we will determine if they should be allowed, denied, dropped, or reset thus speeding up business and decreasing complexity in their environment\n",
        "\n",
        "The goal of the study is to develop and use Support Vector Machine (SVM) and Stochastic gradient descent (SGD) machine learning models. GridSearch and Randomized Search were not leveraged due to the data set size and the time it take to run multiple options (we did attempt but this did fail), but rather we leveraged our own python code to manipulate the various parameters in the algorithms to get an optimal score.   The “Action” feature is the independent variable (y) that will be used predict the whether the firewall traffic should be allowed, denied, dropped, or reset. One data files was received that contained the Firewall data which included over 65,532 records with 12 features.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrSgrPy-yVZZ"
      },
      "source": [
        "print(\"Firewall Dataset - Rows:\", fw.shape[0], \"Columns/Features\", fw.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ze2X5I3mypzu"
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "After analyzing the data, it was discovered that that was a multiclass prediction specifically on the Action field.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpDEX4Csysk1"
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "After analyzing the data, it was discovered that that was a multiclass prediction specifically on the Action field.  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4z7UdfzyOh0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OB0oeQYpyOkg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J65yxl5sx-Fx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqJAz5f-x-IS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Xfdlg9x-Ki"
      },
      "source": [
        "# Start Code"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h31yOyrLxNQ4"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns \n",
        "from sklearn.metrics import classification_report, plot_confusion_matrix\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylm4-3QTxc68"
      },
      "source": [
        "df_Org = pd.read_csv('/content/drive/MyDrive/final_project.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "O1Zk2vULxn9v",
        "outputId": "3f944ee5-ea0b-4603-c6dc-ee0318d6c31d"
      },
      "source": [
        "df_Org.head() "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x0</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>x3</th>\n",
              "      <th>x4</th>\n",
              "      <th>x5</th>\n",
              "      <th>x6</th>\n",
              "      <th>x7</th>\n",
              "      <th>x8</th>\n",
              "      <th>x9</th>\n",
              "      <th>x10</th>\n",
              "      <th>x11</th>\n",
              "      <th>x12</th>\n",
              "      <th>x13</th>\n",
              "      <th>x14</th>\n",
              "      <th>x15</th>\n",
              "      <th>x16</th>\n",
              "      <th>x17</th>\n",
              "      <th>x18</th>\n",
              "      <th>x19</th>\n",
              "      <th>x20</th>\n",
              "      <th>x21</th>\n",
              "      <th>x22</th>\n",
              "      <th>x23</th>\n",
              "      <th>x24</th>\n",
              "      <th>x25</th>\n",
              "      <th>x26</th>\n",
              "      <th>x27</th>\n",
              "      <th>x28</th>\n",
              "      <th>x29</th>\n",
              "      <th>x30</th>\n",
              "      <th>x31</th>\n",
              "      <th>x32</th>\n",
              "      <th>x33</th>\n",
              "      <th>x34</th>\n",
              "      <th>x35</th>\n",
              "      <th>x36</th>\n",
              "      <th>x37</th>\n",
              "      <th>x38</th>\n",
              "      <th>x39</th>\n",
              "      <th>x40</th>\n",
              "      <th>x41</th>\n",
              "      <th>x42</th>\n",
              "      <th>x43</th>\n",
              "      <th>x44</th>\n",
              "      <th>x45</th>\n",
              "      <th>x46</th>\n",
              "      <th>x47</th>\n",
              "      <th>x48</th>\n",
              "      <th>x49</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.166563</td>\n",
              "      <td>-3.961588</td>\n",
              "      <td>4.621113</td>\n",
              "      <td>2.481908</td>\n",
              "      <td>-1.800135</td>\n",
              "      <td>0.804684</td>\n",
              "      <td>6.718751</td>\n",
              "      <td>-14.789997</td>\n",
              "      <td>-1.040673</td>\n",
              "      <td>-4.204950</td>\n",
              "      <td>6.187465</td>\n",
              "      <td>13.251523</td>\n",
              "      <td>25.665413</td>\n",
              "      <td>-5.017267</td>\n",
              "      <td>10.503714</td>\n",
              "      <td>-2.517678</td>\n",
              "      <td>2.117910</td>\n",
              "      <td>5.865923</td>\n",
              "      <td>-6.666158</td>\n",
              "      <td>1.791497</td>\n",
              "      <td>-1.909114</td>\n",
              "      <td>-1.737940</td>\n",
              "      <td>-2.516715</td>\n",
              "      <td>3.553013</td>\n",
              "      <td>euorpe</td>\n",
              "      <td>-0.801340</td>\n",
              "      <td>1.142950</td>\n",
              "      <td>1.005131</td>\n",
              "      <td>-18.473784</td>\n",
              "      <td>July</td>\n",
              "      <td>tuesday</td>\n",
              "      <td>-3.851669</td>\n",
              "      <td>0.0%</td>\n",
              "      <td>-1.940031</td>\n",
              "      <td>-5.492063</td>\n",
              "      <td>0.627121</td>\n",
              "      <td>-0.873824</td>\n",
              "      <td>$1313.96</td>\n",
              "      <td>-1.353729</td>\n",
              "      <td>-5.186148</td>\n",
              "      <td>-10.612200</td>\n",
              "      <td>-1.497117</td>\n",
              "      <td>5.414063</td>\n",
              "      <td>-2.325655</td>\n",
              "      <td>1.674827</td>\n",
              "      <td>-0.264332</td>\n",
              "      <td>60.781427</td>\n",
              "      <td>-7.689696</td>\n",
              "      <td>0.151589</td>\n",
              "      <td>-8.040166</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.149894</td>\n",
              "      <td>-0.585676</td>\n",
              "      <td>27.839856</td>\n",
              "      <td>4.152333</td>\n",
              "      <td>6.426802</td>\n",
              "      <td>-2.426943</td>\n",
              "      <td>40.477058</td>\n",
              "      <td>-6.725709</td>\n",
              "      <td>0.896421</td>\n",
              "      <td>0.330165</td>\n",
              "      <td>-11.708859</td>\n",
              "      <td>-2.352809</td>\n",
              "      <td>-25.014934</td>\n",
              "      <td>9.799608</td>\n",
              "      <td>-10.960705</td>\n",
              "      <td>1.504000</td>\n",
              "      <td>-2.397836</td>\n",
              "      <td>-9.301839</td>\n",
              "      <td>-1.999413</td>\n",
              "      <td>5.045258</td>\n",
              "      <td>-5.809984</td>\n",
              "      <td>10.814319</td>\n",
              "      <td>-0.478112</td>\n",
              "      <td>10.590601</td>\n",
              "      <td>asia</td>\n",
              "      <td>0.818792</td>\n",
              "      <td>-0.642987</td>\n",
              "      <td>0.751086</td>\n",
              "      <td>3.749377</td>\n",
              "      <td>Aug</td>\n",
              "      <td>wednesday</td>\n",
              "      <td>1.391594</td>\n",
              "      <td>-0.02%</td>\n",
              "      <td>2.211462</td>\n",
              "      <td>-4.460591</td>\n",
              "      <td>1.035461</td>\n",
              "      <td>0.228270</td>\n",
              "      <td>$1962.78</td>\n",
              "      <td>32.816804</td>\n",
              "      <td>-5.150012</td>\n",
              "      <td>2.147427</td>\n",
              "      <td>36.292790</td>\n",
              "      <td>4.490915</td>\n",
              "      <td>0.762561</td>\n",
              "      <td>6.526662</td>\n",
              "      <td>1.007927</td>\n",
              "      <td>15.805696</td>\n",
              "      <td>-4.896678</td>\n",
              "      <td>-0.320283</td>\n",
              "      <td>16.719974</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.321707</td>\n",
              "      <td>-1.429819</td>\n",
              "      <td>12.251561</td>\n",
              "      <td>6.586874</td>\n",
              "      <td>-5.304647</td>\n",
              "      <td>-11.311090</td>\n",
              "      <td>17.812850</td>\n",
              "      <td>11.060572</td>\n",
              "      <td>5.325880</td>\n",
              "      <td>-2.632984</td>\n",
              "      <td>1.572647</td>\n",
              "      <td>-4.170771</td>\n",
              "      <td>12.078602</td>\n",
              "      <td>-5.158498</td>\n",
              "      <td>7.302780</td>\n",
              "      <td>-2.192431</td>\n",
              "      <td>-4.065428</td>\n",
              "      <td>-7.675055</td>\n",
              "      <td>4.041629</td>\n",
              "      <td>-6.633628</td>\n",
              "      <td>1.700321</td>\n",
              "      <td>-2.419221</td>\n",
              "      <td>2.467521</td>\n",
              "      <td>-5.270615</td>\n",
              "      <td>asia</td>\n",
              "      <td>-0.718315</td>\n",
              "      <td>-0.566757</td>\n",
              "      <td>4.171088</td>\n",
              "      <td>11.522448</td>\n",
              "      <td>July</td>\n",
              "      <td>wednesday</td>\n",
              "      <td>-3.262082</td>\n",
              "      <td>-0.01%</td>\n",
              "      <td>0.419607</td>\n",
              "      <td>-3.804056</td>\n",
              "      <td>-0.763357</td>\n",
              "      <td>-1.612561</td>\n",
              "      <td>$430.47</td>\n",
              "      <td>-0.333199</td>\n",
              "      <td>8.728585</td>\n",
              "      <td>-0.863137</td>\n",
              "      <td>-0.368491</td>\n",
              "      <td>9.088864</td>\n",
              "      <td>-0.689886</td>\n",
              "      <td>-2.731118</td>\n",
              "      <td>0.754200</td>\n",
              "      <td>30.856417</td>\n",
              "      <td>-7.428573</td>\n",
              "      <td>-2.090804</td>\n",
              "      <td>-7.869421</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.245594</td>\n",
              "      <td>5.076677</td>\n",
              "      <td>-24.149632</td>\n",
              "      <td>3.637307</td>\n",
              "      <td>6.505811</td>\n",
              "      <td>2.290224</td>\n",
              "      <td>-35.111751</td>\n",
              "      <td>-18.913592</td>\n",
              "      <td>-0.337041</td>\n",
              "      <td>-5.568076</td>\n",
              "      <td>-2.000255</td>\n",
              "      <td>-19.286668</td>\n",
              "      <td>10.995330</td>\n",
              "      <td>-5.914378</td>\n",
              "      <td>2.511400</td>\n",
              "      <td>1.292362</td>\n",
              "      <td>-2.496882</td>\n",
              "      <td>-15.722954</td>\n",
              "      <td>-2.735382</td>\n",
              "      <td>1.117536</td>\n",
              "      <td>1.923670</td>\n",
              "      <td>-14.179167</td>\n",
              "      <td>1.470625</td>\n",
              "      <td>-11.484431</td>\n",
              "      <td>asia</td>\n",
              "      <td>-0.052430</td>\n",
              "      <td>-0.558582</td>\n",
              "      <td>9.215569</td>\n",
              "      <td>30.595226</td>\n",
              "      <td>July</td>\n",
              "      <td>wednesday</td>\n",
              "      <td>-2.285241</td>\n",
              "      <td>0.01%</td>\n",
              "      <td>-3.442715</td>\n",
              "      <td>4.420160</td>\n",
              "      <td>1.164532</td>\n",
              "      <td>3.033455</td>\n",
              "      <td>$-2366.29</td>\n",
              "      <td>14.188669</td>\n",
              "      <td>-6.385060</td>\n",
              "      <td>12.084421</td>\n",
              "      <td>15.691546</td>\n",
              "      <td>-7.467775</td>\n",
              "      <td>2.940789</td>\n",
              "      <td>-6.424112</td>\n",
              "      <td>0.419776</td>\n",
              "      <td>-72.424569</td>\n",
              "      <td>5.361375</td>\n",
              "      <td>1.806070</td>\n",
              "      <td>-7.670847</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.273366</td>\n",
              "      <td>0.306326</td>\n",
              "      <td>-11.352593</td>\n",
              "      <td>1.676758</td>\n",
              "      <td>2.928441</td>\n",
              "      <td>-0.616824</td>\n",
              "      <td>-16.505817</td>\n",
              "      <td>27.532281</td>\n",
              "      <td>1.199715</td>\n",
              "      <td>-4.309105</td>\n",
              "      <td>6.667530</td>\n",
              "      <td>1.965913</td>\n",
              "      <td>-28.106348</td>\n",
              "      <td>-1.258950</td>\n",
              "      <td>5.759941</td>\n",
              "      <td>0.472584</td>\n",
              "      <td>-1.150097</td>\n",
              "      <td>-14.118709</td>\n",
              "      <td>4.527964</td>\n",
              "      <td>-1.284372</td>\n",
              "      <td>-9.026317</td>\n",
              "      <td>-7.039818</td>\n",
              "      <td>-1.978748</td>\n",
              "      <td>-15.998166</td>\n",
              "      <td>asia</td>\n",
              "      <td>-0.223449</td>\n",
              "      <td>0.350781</td>\n",
              "      <td>1.811182</td>\n",
              "      <td>-4.094084</td>\n",
              "      <td>July</td>\n",
              "      <td>tuesday</td>\n",
              "      <td>0.921047</td>\n",
              "      <td>0.01%</td>\n",
              "      <td>-0.431640</td>\n",
              "      <td>12.165494</td>\n",
              "      <td>-0.167726</td>\n",
              "      <td>-0.341604</td>\n",
              "      <td>$-620.66</td>\n",
              "      <td>-12.578926</td>\n",
              "      <td>1.133798</td>\n",
              "      <td>30.004727</td>\n",
              "      <td>-13.911297</td>\n",
              "      <td>-5.229937</td>\n",
              "      <td>1.783928</td>\n",
              "      <td>3.957801</td>\n",
              "      <td>-0.096988</td>\n",
              "      <td>-14.085435</td>\n",
              "      <td>-0.208351</td>\n",
              "      <td>-0.894942</td>\n",
              "      <td>15.724742</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         x0        x1         x2        x3  ...       x47       x48        x49  y\n",
              "0 -0.166563 -3.961588   4.621113  2.481908  ... -7.689696  0.151589  -8.040166  0\n",
              "1 -0.149894 -0.585676  27.839856  4.152333  ... -4.896678 -0.320283  16.719974  0\n",
              "2 -0.321707 -1.429819  12.251561  6.586874  ... -7.428573 -2.090804  -7.869421  0\n",
              "3 -0.245594  5.076677 -24.149632  3.637307  ...  5.361375  1.806070  -7.670847  0\n",
              "4 -0.273366  0.306326 -11.352593  1.676758  ... -0.208351 -0.894942  15.724742  1\n",
              "\n",
              "[5 rows x 51 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEziv4ZE7gRl",
        "outputId": "26cc55dc-3295-49c5-983b-395a7c2b70fc"
      },
      "source": [
        "df_Org.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(160000, 51)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkL0PgQJ85LF",
        "outputId": "e431326e-a3e8-4e7b-ccbd-6055569e9ad3"
      },
      "source": [
        "# Drop NA Rows\n",
        "print(\"NA's In Dataset:\",df_Org.isnull().sum().sum())\n",
        "\n",
        "df_Org = df_Org.dropna()\n",
        "print(\"After NA's Dropped:\",(df_Org.isnull().sum().sum()))\n",
        "print(\"Final Shape of Datframe:\", df_Org.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NA's In Dataset: 1608\n",
            "After NA's Dropped: 0\n",
            "Final Shape of Datframe: (158392, 51)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_98_cwQryRch",
        "outputId": "bbeee8cd-6d2b-412c-c7ba-1dac733f5663"
      },
      "source": [
        "# Review Valuecounts\n",
        "for columns in df_Org:\n",
        "    print(df_Org[columns].value_counts())\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.343737    1\n",
            "-0.277255    1\n",
            " 0.093831    1\n",
            "-0.347379    1\n",
            " 0.041180    1\n",
            "            ..\n",
            "-0.267501    1\n",
            " 0.157664    1\n",
            " 0.058046    1\n",
            " 0.271365    1\n",
            " 0.806262    1\n",
            "Name: x0, Length: 158392, dtype: int64\n",
            " 2.753232     1\n",
            " 10.411656    1\n",
            "-0.497376     1\n",
            "-5.379456     1\n",
            "-6.114450     1\n",
            "             ..\n",
            " 3.571226     1\n",
            "-6.312343     1\n",
            " 7.795734     1\n",
            " 2.382735     1\n",
            "-0.104553     1\n",
            "Name: x1, Length: 158392, dtype: int64\n",
            " 1.013149     1\n",
            "-14.083205    1\n",
            "-1.207091     1\n",
            "-3.190369     1\n",
            "-16.303680    1\n",
            "             ..\n",
            "-5.965018     1\n",
            "-18.234312    1\n",
            " 1.430004     1\n",
            "-11.742846    1\n",
            "-7.631792     1\n",
            "Name: x2, Length: 158392, dtype: int64\n",
            " 8.612018     1\n",
            " 2.999966     1\n",
            "-9.591580     1\n",
            " 0.323170     1\n",
            " 13.324483    1\n",
            "             ..\n",
            "-16.742501    1\n",
            " 8.477979     1\n",
            " 9.666829     1\n",
            "-4.553361     1\n",
            " 1.002264     1\n",
            "Name: x3, Length: 158392, dtype: int64\n",
            "-8.237243     1\n",
            "-3.544970     1\n",
            "-4.049198     1\n",
            " 6.435219     1\n",
            " 1.031178     1\n",
            "             ..\n",
            "-6.776208     1\n",
            " 12.516159    1\n",
            "-11.063872    1\n",
            " 0.706205     1\n",
            "-2.423492     1\n",
            "Name: x4, Length: 158392, dtype: int64\n",
            " 1.747008     1\n",
            " 9.252944     1\n",
            " 7.368334     1\n",
            " 0.671852     1\n",
            " 0.037711     1\n",
            "             ..\n",
            "-0.746471     1\n",
            "-1.244649     1\n",
            "-8.553028     1\n",
            "-13.232523    1\n",
            "-5.725937     1\n",
            "Name: x5, Length: 158392, dtype: int64\n",
            "-0.597343     1\n",
            " 11.759209    1\n",
            " 14.147457    1\n",
            "-4.952638     1\n",
            " 0.062771     1\n",
            "             ..\n",
            " 10.581161    1\n",
            " 19.426155    1\n",
            " 17.454115    1\n",
            "-19.727836    1\n",
            "-1.752142     1\n",
            "Name: x6, Length: 158392, dtype: int64\n",
            "-12.625165    1\n",
            " 23.378975    1\n",
            " 8.923300     1\n",
            " 61.496990    1\n",
            " 45.924147    1\n",
            "             ..\n",
            " 4.536371     1\n",
            " 1.537836     1\n",
            " 28.326722    1\n",
            "-74.595826    1\n",
            "-7.004834     1\n",
            "Name: x7, Length: 158392, dtype: int64\n",
            " 3.280245     1\n",
            "-9.106635     1\n",
            "-14.840253    1\n",
            "-24.445101    1\n",
            "-10.681784    1\n",
            "             ..\n",
            "-0.762404     1\n",
            " 0.749874     1\n",
            "-0.650437     1\n",
            " 11.534934    1\n",
            "-6.104345     1\n",
            "Name: x8, Length: 158392, dtype: int64\n",
            " 3.729101     1\n",
            "-2.583684     1\n",
            " 8.917569     1\n",
            " 1.579230     1\n",
            "-13.989836    1\n",
            "             ..\n",
            " 4.418511     1\n",
            " 7.820134     1\n",
            "-9.516596     1\n",
            " 6.535733     1\n",
            " 5.423598     1\n",
            "Name: x9, Length: 158392, dtype: int64\n",
            " 6.466809     1\n",
            " 2.311998     1\n",
            "-14.574329    1\n",
            " 10.139012    1\n",
            "-1.825357     1\n",
            "             ..\n",
            "-7.572195     1\n",
            "-13.204184    1\n",
            " 16.648929    1\n",
            "-2.608374     1\n",
            "-1.411075     1\n",
            "Name: x10, Length: 158392, dtype: int64\n",
            " 4.102017     1\n",
            "-0.458969     1\n",
            "-2.218090     1\n",
            " 1.629688     1\n",
            " 3.604038     1\n",
            "             ..\n",
            " 6.643900     1\n",
            "-4.258962     1\n",
            "-2.784081     1\n",
            " 5.012945     1\n",
            " 13.391709    1\n",
            "Name: x11, Length: 158392, dtype: int64\n",
            " 5.313896     1\n",
            "-15.873788    1\n",
            "-1.457228     1\n",
            "-7.325357     1\n",
            "-6.997951     1\n",
            "             ..\n",
            "-17.234481    1\n",
            "-2.773384     1\n",
            "-29.760494    1\n",
            "-23.508682    1\n",
            " 7.215984     1\n",
            "Name: x12, Length: 158392, dtype: int64\n",
            "-4.639837     1\n",
            "-14.777296    1\n",
            " 5.455694     1\n",
            "-1.213294     1\n",
            " 8.976390     1\n",
            "             ..\n",
            "-5.007008     1\n",
            " 5.141446     1\n",
            " 5.826504     1\n",
            " 11.976048    1\n",
            "-6.006601     1\n",
            "Name: x13, Length: 158392, dtype: int64\n",
            "-1.214372     1\n",
            " 8.691712     1\n",
            " 5.607039     1\n",
            " 4.099157     1\n",
            " 2.157451     1\n",
            "             ..\n",
            " 12.764373    1\n",
            "-0.372640     1\n",
            " 6.104826     1\n",
            "-3.781191     1\n",
            " 15.669487    1\n",
            "Name: x14, Length: 158392, dtype: int64\n",
            " 0.533868    1\n",
            "-7.496869    1\n",
            " 0.956618    1\n",
            " 0.380507    1\n",
            "-0.403627    1\n",
            "            ..\n",
            "-1.862383    1\n",
            " 0.157013    1\n",
            " 4.205896    1\n",
            "-4.851712    1\n",
            "-4.327166    1\n",
            "Name: x15, Length: 158392, dtype: int64\n",
            "-1.412537    1\n",
            "-6.477659    1\n",
            " 2.752143    1\n",
            "-5.281499    1\n",
            "-3.972552    1\n",
            "            ..\n",
            "-0.369898    1\n",
            "-4.034932    1\n",
            "-0.539312    1\n",
            " 9.653685    1\n",
            "-3.384628    1\n",
            "Name: x16, Length: 158392, dtype: int64\n",
            " 9.297413     1\n",
            "-14.852920    1\n",
            " 10.439870    1\n",
            " 4.880301     1\n",
            "-6.530892     1\n",
            "             ..\n",
            "-5.725504     1\n",
            "-5.311613     1\n",
            "-3.148759     1\n",
            "-10.696288    1\n",
            " 7.348655     1\n",
            "Name: x17, Length: 158392, dtype: int64\n",
            "-1.654769    1\n",
            " 6.945437    1\n",
            "-1.957687    1\n",
            "-0.332518    1\n",
            "-3.397805    1\n",
            "            ..\n",
            "-0.695998    1\n",
            " 1.139433    1\n",
            " 1.427735    1\n",
            " 4.773760    1\n",
            "-5.981008    1\n",
            "Name: x18, Length: 158392, dtype: int64\n",
            " 5.877477     1\n",
            " 2.410535     1\n",
            " 3.129218     1\n",
            "-3.010973     1\n",
            " 0.863634     1\n",
            "             ..\n",
            " 1.395223     1\n",
            "-1.711177     1\n",
            "-13.875043    1\n",
            " 10.132028    1\n",
            " 15.171636    1\n",
            "Name: x19, Length: 158392, dtype: int64\n",
            "-4.736268    1\n",
            "-4.291051    1\n",
            " 3.252299    1\n",
            "-0.966470    1\n",
            " 0.241216    1\n",
            "            ..\n",
            "-2.597258    1\n",
            "-0.574298    1\n",
            " 0.345697    1\n",
            "-2.455216    1\n",
            "-3.891969    1\n",
            "Name: x20, Length: 158392, dtype: int64\n",
            "-0.566362     1\n",
            " 0.775156     1\n",
            " 6.280845     1\n",
            " 23.565640    1\n",
            " 4.777265     1\n",
            "             ..\n",
            "-7.033046     1\n",
            " 15.089717    1\n",
            " 10.390514    1\n",
            "-1.514543     1\n",
            " 2.238164     1\n",
            "Name: x21, Length: 158392, dtype: int64\n",
            "-5.026989    1\n",
            " 2.144024    1\n",
            "-2.495453    1\n",
            "-1.686349    1\n",
            "-0.337406    1\n",
            "            ..\n",
            "-1.193106    1\n",
            " 7.114742    1\n",
            "-3.154151    1\n",
            " 4.065652    1\n",
            "-1.352278    1\n",
            "Name: x22, Length: 158392, dtype: int64\n",
            " 3.770221     1\n",
            " 9.364475     1\n",
            "-18.776134    1\n",
            " 23.255902    1\n",
            "-13.478567    1\n",
            "             ..\n",
            " 19.041451    1\n",
            " 10.470118    1\n",
            " 27.870104    1\n",
            " 2.197952     1\n",
            "-11.105365    1\n",
            "Name: x23, Length: 158392, dtype: int64\n",
            "asia       137596\n",
            "euorpe      16378\n",
            "america      4418\n",
            "Name: x24, dtype: int64\n",
            "-2.103266    1\n",
            "-1.687875    1\n",
            "-0.272529    1\n",
            "-1.400937    1\n",
            "-0.636944    1\n",
            "            ..\n",
            " 1.930528    1\n",
            "-0.856456    1\n",
            "-0.179260    1\n",
            " 0.351698    1\n",
            "-0.140098    1\n",
            "Name: x25, Length: 158392, dtype: int64\n",
            "-0.563795    1\n",
            " 0.632197    1\n",
            "-0.451706    1\n",
            "-0.383397    1\n",
            " 0.328192    1\n",
            "            ..\n",
            "-0.138221    1\n",
            " 0.925413    1\n",
            "-0.336525    1\n",
            "-0.375229    1\n",
            "-0.692562    1\n",
            "Name: x26, Length: 158392, dtype: int64\n",
            "-0.980662     1\n",
            " 3.313281     1\n",
            " 0.732085     1\n",
            "-0.654037     1\n",
            " 10.079691    1\n",
            "             ..\n",
            " 2.139238     1\n",
            " 1.157180     1\n",
            "-7.874146     1\n",
            "-6.520252     1\n",
            " 2.273132     1\n",
            "Name: x27, Length: 158392, dtype: int64\n",
            "-27.238384    1\n",
            "-13.159622    1\n",
            "-13.946682    1\n",
            "-23.966163    1\n",
            "-10.668205    1\n",
            "             ..\n",
            " 14.315478    1\n",
            " 13.173318    1\n",
            "-11.497401    1\n",
            "-13.461814    1\n",
            "-13.214627    1\n",
            "Name: x28, Length: 158392, dtype: int64\n",
            "July       45122\n",
            "Jun        40900\n",
            "Aug        29115\n",
            "May        21708\n",
            "sept.      10740\n",
            "Apr         6699\n",
            "Oct         2385\n",
            "Mar         1221\n",
            "Nov          331\n",
            "Feb          139\n",
            "Dev           23\n",
            "January        9\n",
            "Name: x29, dtype: int64\n",
            "wednesday    100498\n",
            "thurday       29164\n",
            "tuesday       27690\n",
            "friday          556\n",
            "monday          484\n",
            "Name: x30, dtype: int64\n",
            "-2.070134    1\n",
            " 6.635515    1\n",
            " 0.583013    1\n",
            " 0.612386    1\n",
            "-3.661723    1\n",
            "            ..\n",
            " 3.101575    1\n",
            "-1.234094    1\n",
            " 0.969227    1\n",
            "-3.171279    1\n",
            "-3.517466    1\n",
            "Name: x31, Length: 158392, dtype: int64\n",
            "0.01%     40367\n",
            "-0.01%    33771\n",
            "0.0%      33556\n",
            "-0.0%     30224\n",
            "-0.02%     9812\n",
            "0.02%      7911\n",
            "-0.03%     1709\n",
            "0.03%       845\n",
            "-0.04%      136\n",
            "0.04%        54\n",
            "-0.05%        6\n",
            "0.05%         1\n",
            "Name: x32, dtype: int64\n",
            " 1.039158    1\n",
            "-2.336318    1\n",
            " 0.607779    1\n",
            "-1.903235    1\n",
            " 3.291017    1\n",
            "            ..\n",
            "-0.032526    1\n",
            "-0.208061    1\n",
            " 0.659764    1\n",
            " 0.719857    1\n",
            "-1.493854    1\n",
            "Name: x33, Length: 158392, dtype: int64\n",
            "-4.359749     1\n",
            " 2.880358     1\n",
            " 15.821545    1\n",
            " 8.995988     1\n",
            "-1.046174     1\n",
            "             ..\n",
            "-3.313797     1\n",
            " 6.054635     1\n",
            "-4.475766     1\n",
            " 1.600502     1\n",
            " 12.852956    1\n",
            "Name: x34, Length: 158392, dtype: int64\n",
            "-1.772883    1\n",
            " 0.034151    1\n",
            " 0.826293    1\n",
            "-0.111125    1\n",
            "-1.004553    1\n",
            "            ..\n",
            " 2.122296    1\n",
            " 0.181145    1\n",
            " 2.859128    1\n",
            "-1.083040    1\n",
            " 0.607196    1\n",
            "Name: x35, Length: 158392, dtype: int64\n",
            "-1.208768    1\n",
            "-0.532929    1\n",
            " 2.842657    1\n",
            "-0.271383    1\n",
            "-1.758758    1\n",
            "            ..\n",
            " 0.401990    1\n",
            "-2.384122    1\n",
            " 2.788397    1\n",
            " 0.431687    1\n",
            "-2.069247    1\n",
            "Name: x36, Length: 158392, dtype: int64\n",
            "$-336.77     6\n",
            "$-311.26     6\n",
            "$618.22      6\n",
            "$-415.46     6\n",
            "$341.26      6\n",
            "            ..\n",
            "$-1391.69    1\n",
            "$-1760.31    1\n",
            "$-2052.07    1\n",
            "$985.77      1\n",
            "$1434.62     1\n",
            "Name: x37, Length: 128126, dtype: int64\n",
            " 54.514546    1\n",
            "-8.101157     1\n",
            "-51.762493    1\n",
            " 18.177662    1\n",
            " 31.024453    1\n",
            "             ..\n",
            " 36.588813    1\n",
            " 6.647796     1\n",
            "-1.122243     1\n",
            "-4.140784     1\n",
            " 5.374566     1\n",
            "Name: x38, Length: 158392, dtype: int64\n",
            " 4.814956     1\n",
            "-0.956528     1\n",
            "-11.219993    1\n",
            " 5.119073     1\n",
            " 1.202756     1\n",
            "             ..\n",
            "-3.640870     1\n",
            "-2.233182     1\n",
            "-0.346338     1\n",
            " 2.554497     1\n",
            " 4.655905     1\n",
            "Name: x39, Length: 158392, dtype: int64\n",
            " 3.084098     1\n",
            " 5.766342     1\n",
            "-13.574382    1\n",
            "-35.612193    1\n",
            "-11.442653    1\n",
            "             ..\n",
            "-6.517702     1\n",
            "-7.520650     1\n",
            "-10.588341    1\n",
            " 21.940018    1\n",
            " 33.660863    1\n",
            "Name: x40, Length: 158392, dtype: int64\n",
            " 5.422539     1\n",
            " 3.779243     1\n",
            " 11.646614    1\n",
            "-2.149669     1\n",
            " 20.708411    1\n",
            "             ..\n",
            " 22.298359    1\n",
            " 31.826503    1\n",
            "-7.020295     1\n",
            " 34.227560    1\n",
            " 15.182755    1\n",
            "Name: x41, Length: 158392, dtype: int64\n",
            " 5.526654     1\n",
            "-7.614139     1\n",
            " 3.008056     1\n",
            "-1.838761     1\n",
            "-12.667975    1\n",
            "             ..\n",
            "-2.067793     1\n",
            "-15.251754    1\n",
            "-2.876408     1\n",
            "-3.780674     1\n",
            "-3.819440     1\n",
            "Name: x42, Length: 158392, dtype: int64\n",
            " 0.021450    1\n",
            " 0.901697    1\n",
            " 3.146389    1\n",
            " 2.152255    1\n",
            "-3.379170    1\n",
            "            ..\n",
            "-0.322854    1\n",
            " 3.264950    1\n",
            " 0.487797    1\n",
            " 3.231631    1\n",
            "-0.519442    1\n",
            "Name: x43, Length: 158392, dtype: int64\n",
            "-1.889892    1\n",
            "-6.201020    1\n",
            "-7.737160    1\n",
            "-1.976247    1\n",
            " 3.930186    1\n",
            "            ..\n",
            "-0.239856    1\n",
            " 4.220636    1\n",
            "-1.619608    1\n",
            " 1.940743    1\n",
            " 0.350381    1\n",
            "Name: x44, Length: 158392, dtype: int64\n",
            "-0.282880    1\n",
            " 0.395816    1\n",
            "-0.230732    1\n",
            " 0.410828    1\n",
            " 0.120153    1\n",
            "            ..\n",
            "-0.055491    1\n",
            "-0.088071    1\n",
            " 0.911593    1\n",
            " 0.336439    1\n",
            " 0.624602    1\n",
            "Name: x45, Length: 158392, dtype: int64\n",
            "-15.996361    1\n",
            "-53.766217    1\n",
            " 47.004192    1\n",
            "-17.426853    1\n",
            "-27.400170    1\n",
            "             ..\n",
            " 15.220187    1\n",
            " 5.265200     1\n",
            "-19.838260    1\n",
            "-7.499364     1\n",
            " 2.085575     1\n",
            "Name: x46, Length: 158392, dtype: int64\n",
            "-2.657502    1\n",
            " 2.267603    1\n",
            "-5.158991    1\n",
            " 1.177841    1\n",
            "-1.047744    1\n",
            "            ..\n",
            " 4.678173    1\n",
            "-6.923510    1\n",
            "-4.687349    1\n",
            " 5.181113    1\n",
            " 2.440033    1\n",
            "Name: x47, Length: 158392, dtype: int64\n",
            "-3.669496    1\n",
            " 0.810832    1\n",
            "-0.149397    1\n",
            " 0.957255    1\n",
            " 0.141778    1\n",
            "            ..\n",
            " 1.695486    1\n",
            " 0.595352    1\n",
            " 2.069427    1\n",
            "-2.903996    1\n",
            " 0.250464    1\n",
            "Name: x48, Length: 158392, dtype: int64\n",
            " 0.578675     1\n",
            " 6.915066     1\n",
            " 30.857158    1\n",
            "-15.798063    1\n",
            "-23.353691    1\n",
            "             ..\n",
            " 17.180613    1\n",
            "-16.507838    1\n",
            "-32.390649    1\n",
            "-4.949545     1\n",
            "-22.058109    1\n",
            "Name: x49, Length: 158392, dtype: int64\n",
            "0    94846\n",
            "1    63546\n",
            "Name: y, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0JLxzYESdGN"
      },
      "source": [
        "# Attempted Feature Engineering"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUvSfdPIzBE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "998109f7-c575-4422-f985-6277cc7a7910"
      },
      "source": [
        "print(\"Did not Use this as it Didn't Improve Accuracy\")\n",
        "# df = df_Org.copy()\n",
        "# df = df.rename(columns = {'x24': 'region', \n",
        "#                           'x29': 'month', \n",
        "#                           'x30': 'weekday', }, inplace = False)   \n",
        "\n",
        "# catagorical_Variables = ['region','month','weekday']\n",
        "# df_Catagorical_Only = df[catagorical_Variables]\n",
        "# df_Catagorical_Only.dtypes\n",
        "# df_Catgorical_DF = pd.get_dummies(df_Catagorical_Only, drop_first=True) # This has all the dummies\n",
        "\n",
        "\n",
        "# # df_Catagorical_Only.dtypes\n",
        "# # for columns in df_Catagorical_Only:\n",
        "# #     print(df_Catagorical_Only[columns].value_counts())\n",
        "\n",
        "# # Convert Numeric\n",
        "# numberic_Variables = ['x37', 'x32']\n",
        "# df_numerical_Only = df[numberic_Variables]\n",
        "# df_numerical_Only['x37'] = df_numerical_Only['x37'].replace({'\\$':''}, regex = True)\n",
        "# df_numerical_Only['x37'] = df_numerical_Only['x37'].astype('float')\n",
        "# df_numerical_Only['x32'] = df_numerical_Only['x32'].replace({'\\%':''}, regex = True)\n",
        "# df_numerical_Only['x32'] = df_numerical_Only['x32'].astype('float')\n",
        "\n",
        "\n",
        "# # Get Disceet Values for Scaler\n",
        "# df_Discreet = df.drop(labels=catagorical_Variables, axis=1)\n",
        "# df_Discreet = df_Discreet.drop(labels=numberic_Variables, axis=1)\n",
        "# df_Discreet = df_Discreet.drop('y', axis=1)\n",
        "\n",
        "# # df_Discreet.head()\n",
        "# # for columns in df_Discreet:\n",
        "# #     print(df_Discreet[columns].value_counts())\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "# df_Discreet_Scaled = scaler.fit_transform(df_Discreet)\n",
        "# df_Discreet_Scaled = pd.DataFrame(df_Discreet_Scaled, columns = df_Discreet.columns)\n",
        "# print(\"Scaled Discete\", df_Discreet_Scaled.shape)\n",
        "\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Did not Use this as it Didn't Improve Accuracy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sJeSPkt8pED"
      },
      "source": [
        "# # Join Dataset\n",
        "# df_Clean = pd.merge(df_Discreet_Scaled, df_Catgorical_DF, left_index=True, right_index=True) # Join Discreet/Scaled and Catagorical\n",
        "# df_Clean = pd.merge(df_Clean, df_numerical_Only, left_index=True, right_index=True) # Joing Above with Numberical\n",
        "# df_Clean['y'] = df_Org['y'] # ADD Y\n",
        "# print(\"Cleaned Dataset Size:\", df_Clean.shape)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lGSFqxdD0R47"
      },
      "source": [
        "# Coorelatoins"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWdhMsYqxt6k"
      },
      "source": [
        "# # Test Coor\n",
        "# # Coorelation\n",
        "# correlated_features = set()\n",
        "\n",
        "# correlation_matrix = df_Clean.corr()\n",
        "\n",
        "# coor_Delete = .90\n",
        "# corList = []\n",
        "# for i in range(len(correlation_matrix.columns)):\n",
        "# #     print(\"I\", i) \n",
        "#     for j in range(i):\n",
        "# #         print(\"J\", j) \n",
        "# #             print(\"Val\", abs(correlation_matrix.iloc[i, j])\n",
        "#         if abs(correlation_matrix.iloc[i, j]) > coor_Delete: \n",
        "#             val= abs(correlation_matrix.iloc[i, j])\n",
        "#             colname = correlation_matrix.columns[i]\n",
        "#             corList.append({\n",
        "#                 \"colum_Name\": colname, \n",
        "#                 \"value_Corr\": val})\n",
        "#             correlated_features.add(colname)\n",
        "\n",
        "# print(\"Number of Highly Correlated Features\", len(correlated_features))\n",
        "# correlated_features\n",
        "\n",
        "# # X.drop(labels=correlated_features, axis=1, inplace=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJt-SFAR_oXK"
      },
      "source": [
        "# sns.pairplot(df_Clean[correlated_features])\n",
        "# df_Corr = df_Clean.drop(['x41' ], axis=1) # Removed 1 Coorlate Feature\n",
        "# # df_Corr = df_Clean.drop(['x41' ], axis=1) # Removed 1 Coorlate Feature\n",
        "# df_Corr.head()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHusi2AH_veR"
      },
      "source": [
        "# #  From Dr. Drew Machine Learning 1 Class\n",
        "# def exclude_high_freq(X_df: pd.DataFrame, freq_pct=.90, verbose=False):\n",
        "#     \"\"\"Dataset that excludes high-frequent fields\"\"\"\n",
        "#     result = []\n",
        "#     for col in X_df.columns:\n",
        "#         df = X_df[col].value_counts().reset_index()\n",
        "#         df.columns = [\"value\", \"ct\"]\n",
        "#         df[\"Column\"] = col\n",
        "#         df[\"pct\"] = df.ct / len(X_df)\n",
        "#         result.append(df.head(5))\n",
        "\n",
        "#     df_agg = pd.concat(result, axis=0).groupby([\"Column\"])[\"pct\"].max()\n",
        "\n",
        "#     cols_to_delete = df_agg[df_agg > freq_pct].index.values.tolist()\n",
        "   \n",
        "#     if verbose:\n",
        "#         print(\"Columns we will delete:\")\n",
        "#         df = pd.concat(result, axis=0)\n",
        "#         df[\"val-count\"] = df[\"value\"].astype(str) + \" (\" + round(df.pct,2).astype(str) + \")\"\n",
        "#         display(df[df[\"Column\"].isin(cols_to_delete)].groupby([\"Column\"])[\"val-count\"].apply(list))\n",
        "   \n",
        "#     X_df = X_df.drop(cols_to_delete, axis=1).copy()\n",
        "\n",
        "       \n",
        "#     return X_df\n",
        "\n",
        "# df_HighFreq = exclude_high_freq(df_Corr, verbose=True)\n",
        "\n",
        "# print(\"Shape Before High Frequency Fields Removed:\", df_Corr.shape)\n",
        "# print(\"Shape After High Frequency Fields Woudl be Remove:\", df_HighFreq.shape)\n",
        "# print(\"\")\n",
        "# print(\"*** Important *** After Further Review,  Not Removing Fields because these are the Get Dummy Numbers and are to be expected\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_egBDqGyEK0e"
      },
      "source": [
        "# # Finalize Dataset\n",
        "# df_Final = df_HighFreq.copy()\n",
        "# df_Final.head()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34T7AZToSo1v"
      },
      "source": [
        "# Dropping Catagorical and Numberic Features"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEtsdgpd-Efm"
      },
      "source": [
        "# Drop Datasets for Numerica and Catagorical\n",
        "df_Final = df_Org.drop(['x37', 'x32', 'x24', 'x29', 'x30'], axis=1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_VN2d1OSs8I"
      },
      "source": [
        "# Testing for Balance"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wbkqi_bae7QT",
        "outputId": "ae702e66-6b28-43a2-e0f2-d28e28d7966d"
      },
      "source": [
        "df_Final['y'].value_counts()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    94846\n",
              "1    63546\n",
              "Name: y, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQx_Sjc8Svyl"
      },
      "source": [
        "# Setup DF"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRlzFysiC3Kz",
        "outputId": "29e7165d-18b1-4efc-ee02-4ecfaa5f24ac"
      },
      "source": [
        "# Setup Dataset\n",
        "X = df_Final\n",
        "X = X.drop(['y'], axis=1)\n",
        "y = df_Final['y']\n",
        "y = y.astype('int')\n",
        "print(X.shape)\n",
        "len(y)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(158392, 45)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "158392"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QLHaGdve6f4",
        "outputId": "e6d72dbf-fc50-4221-bc5e-7692d685b031"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=76)\n",
        "print('X', X.shape)\n",
        "print('X_train', X_train.shape)\n",
        "print('X_test', X_test.shape)\n",
        "print('y_train', y_train.shape)\n",
        "print('y_test', y_test.shape)\n",
        "print(\"Test%\", (X_test.shape[0]/X.shape[0]))\n",
        "print(\"Train%\", (X_train.shape[0]/X.shape[0]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X (158392, 45)\n",
            "X_train (110874, 45)\n",
            "X_test (47518, 45)\n",
            "y_train (110874,)\n",
            "y_test (47518,)\n",
            "Test% 0.3000025253800697\n",
            "Train% 0.6999974746199303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GQ5mzZJE0BN"
      },
      "source": [
        "# Logistic Regression"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2c5L81YE2D7",
        "outputId": "3470cfa1-4f51-4040-cb00-390504d5380e"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "lr = LogisticRegression(max_iter=10000, random_state=447788)\n",
        "lr_CVS = cross_val_score(lr, X, y, scoring='accuracy', error_score=\"raise\", n_jobs=-1)\n",
        "lr_CVS"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.7001168 , 0.70346286, 0.7022855 , 0.70253804, 0.7045268 ])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN43rU83-xPI",
        "outputId": "421984ee-4c7d-405a-ed5e-35af9077baf5"
      },
      "source": [
        "# Feature Selection\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LassoCV\n",
        "split = KFold(shuffle=True)\n",
        "lasso_SC = LassoCV(cv = split)\n",
        "lasso_SC.fit(X, y)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.247e+02, tolerance: 3.805e+00\n",
            "  coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LassoCV(cv=KFold(n_splits=5, random_state=None, shuffle=True))"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHJKr3ZO_Q3c"
      },
      "source": [
        "feature_List = []\n",
        "for i in range(len(X.columns)):\n",
        "    feature_List.append({\n",
        "        'name': X.columns[i],\n",
        "        'coef': lasso_SC.coef_[i]\n",
        "        })\n",
        "    "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "oLHMTW2R_Q8N",
        "outputId": "9b82b1ac-e875-457e-85ed-07b971bd8c80"
      },
      "source": [
        "features_SC = pd.DataFrame.from_dict(feature_List)\n",
        "final_Features = features_SC.loc[features_SC[\"coef\"] != 0,:]\n",
        "final_Features.shape\n",
        "final_Features\n",
        "\n",
        "final_Features.sort_values(by='name', ascending=False)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>coef</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>x9</td>\n",
              "      <td>0.000007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>x8</td>\n",
              "      <td>-0.000220</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>x7</td>\n",
              "      <td>-0.003202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>x6</td>\n",
              "      <td>-0.001188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>x5</td>\n",
              "      <td>-0.000006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>x49</td>\n",
              "      <td>0.007517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>x48</td>\n",
              "      <td>-0.012605</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>x46</td>\n",
              "      <td>-0.001047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>x42</td>\n",
              "      <td>-0.001231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>x40</td>\n",
              "      <td>-0.000712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>x4</td>\n",
              "      <td>0.000018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>x34</td>\n",
              "      <td>0.000244</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>x3</td>\n",
              "      <td>0.000103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>x28</td>\n",
              "      <td>0.002862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>x23</td>\n",
              "      <td>-0.010649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>x21</td>\n",
              "      <td>0.000110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>x20</td>\n",
              "      <td>-0.017980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>x19</td>\n",
              "      <td>0.000170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>x18</td>\n",
              "      <td>0.000275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>x17</td>\n",
              "      <td>-0.000088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>x16</td>\n",
              "      <td>0.000370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>x14</td>\n",
              "      <td>-0.000057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>x13</td>\n",
              "      <td>-0.000063</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>x12</td>\n",
              "      <td>-0.003456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>x11</td>\n",
              "      <td>0.000014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>x10</td>\n",
              "      <td>-0.000052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>x1</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   name      coef\n",
              "9    x9  0.000007\n",
              "8    x8 -0.000220\n",
              "7    x7 -0.003202\n",
              "6    x6 -0.001188\n",
              "5    x5 -0.000006\n",
              "44  x49  0.007517\n",
              "43  x48 -0.012605\n",
              "41  x46 -0.001047\n",
              "37  x42 -0.001231\n",
              "35  x40 -0.000712\n",
              "4    x4  0.000018\n",
              "30  x34  0.000244\n",
              "3    x3  0.000103\n",
              "27  x28  0.002862\n",
              "23  x23 -0.010649\n",
              "21  x21  0.000110\n",
              "20  x20 -0.017980\n",
              "19  x19  0.000170\n",
              "18  x18  0.000275\n",
              "17  x17 -0.000088\n",
              "16  x16  0.000370\n",
              "14  x14 -0.000057\n",
              "13  x13 -0.000063\n",
              "12  x12 -0.003456\n",
              "11  x11  0.000014\n",
              "10  x10 -0.000052\n",
              "1    x1  0.000200"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "i_hUUlcwCD4i",
        "outputId": "9aa19306-9aad-4001-949d-58e9bcabe9a9"
      },
      "source": [
        "C = np.array([.001, .01, .1, .2, .25, .50, .75, .99])\n",
        "c_result = []\n",
        "for i in C:\n",
        "    lr.C = i\n",
        "    out = cross_val_score(lr, X, y, scoring='accuracy', n_jobs=-1,)\n",
        "    print(i, out.mean(),out.std())\n",
        "    c_result.append({\n",
        "        'C': i,\n",
        "        'Mean': out.mean(),\n",
        "        'STD': out.std()\n",
        "    })\n",
        "\n",
        "c_Value_DF_Man = pd.DataFrame(c_result)\n",
        "# c_Value_DF_Man.to_csv('pickle/c_Value_DF_Man.csv')\n",
        "display(c_Value_DF_Man)  \n",
        "    \n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.001 0.7025481186630564 0.0015533005855017507\n",
            "0.01 0.70256705925274 0.0014678910869191314\n",
            "0.1 0.7025923129737244 0.0014738955846499088\n",
            "0.2 0.7025923135716153 0.001468899138713409\n",
            "0.25 0.702598626503619 0.0014545235599267414\n",
            "0.5 0.7025481188623534 0.0014571338602914533\n",
            "0.75 0.7025860000417208 0.0014528168014979873\n",
            "0.99 0.7025733727826348 0.0014612894121072027\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C</th>\n",
              "      <th>Mean</th>\n",
              "      <th>STD</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001</td>\n",
              "      <td>0.702548</td>\n",
              "      <td>0.001553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.010</td>\n",
              "      <td>0.702567</td>\n",
              "      <td>0.001468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.100</td>\n",
              "      <td>0.702592</td>\n",
              "      <td>0.001474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.200</td>\n",
              "      <td>0.702592</td>\n",
              "      <td>0.001469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.250</td>\n",
              "      <td>0.702599</td>\n",
              "      <td>0.001455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.500</td>\n",
              "      <td>0.702548</td>\n",
              "      <td>0.001457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.750</td>\n",
              "      <td>0.702586</td>\n",
              "      <td>0.001453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.990</td>\n",
              "      <td>0.702573</td>\n",
              "      <td>0.001461</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       C      Mean       STD\n",
              "0  0.001  0.702548  0.001553\n",
              "1  0.010  0.702567  0.001468\n",
              "2  0.100  0.702592  0.001474\n",
              "3  0.200  0.702592  0.001469\n",
              "4  0.250  0.702599  0.001455\n",
              "5  0.500  0.702548  0.001457\n",
              "6  0.750  0.702586  0.001453\n",
              "7  0.990  0.702573  0.001461"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4JsS_JZFbC-"
      },
      "source": [
        "# Randomized Search - Random Forest"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7kQkoAG6owC",
        "outputId": "efeebdff-2bb7-430a-b55b-cacddd4cffa4"
      },
      "source": [
        "print(\"Final Model from Local\")\n",
        "# # Final Model\n",
        "# from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Model from Local\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w4gn-4vDVmOr"
      },
      "source": [
        "rf = RandomForestClassifier(n_jobs=-1)\n",
        "\n",
        "tuned_parameters = {'n_estimators': [10,50, 100, 300, 500], \n",
        "                    'criterion': ['gini', 'entropy'],\n",
        "                    'max_depth':[5,10,15],\n",
        "                    'min_samples_split':[2,4,9] \n",
        "                   }\n",
        "scores = ['precision', 'recall']"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAvuhExeadSM",
        "outputId": "eb919405-2e08-41a8-f8d4-a38ab13dfc0f"
      },
      "source": [
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for ********* %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = RandomizedSearchCV(RandomForestClassifier(), tuned_parameters, cv=5, n_iter=30, scoring='%s_macro' % score\n",
        "    )\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "#     y_true, y_pred = y_test, clf.predict(X_test) # NEed to Add Back \n",
        "#     print(classification_report(y_true, y_pred)) # NEed to Add Back\n",
        "    print()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Tuning hyper-parameters for ********* precision\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'n_estimators': 500, 'min_samples_split': 4, 'max_depth': 15, 'criterion': 'entropy'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.758 (+/-0.018) for {'n_estimators': 10, 'min_samples_split': 2, 'max_depth': 5, 'criterion': 'entropy'}\n",
            "0.854 (+/-0.001) for {'n_estimators': 10, 'min_samples_split': 2, 'max_depth': 10, 'criterion': 'gini'}\n",
            "0.880 (+/-0.007) for {'n_estimators': 10, 'min_samples_split': 4, 'max_depth': 15, 'criterion': 'gini'}\n",
            "0.899 (+/-0.008) for {'n_estimators': 50, 'min_samples_split': 2, 'max_depth': 15, 'criterion': 'gini'}\n",
            "0.774 (+/-0.011) for {'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 5, 'criterion': 'entropy'}\n",
            "0.872 (+/-0.005) for {'n_estimators': 500, 'min_samples_split': 4, 'max_depth': 10, 'criterion': 'gini'}\n",
            "0.879 (+/-0.007) for {'n_estimators': 10, 'min_samples_split': 2, 'max_depth': 15, 'criterion': 'gini'}\n",
            "0.903 (+/-0.006) for {'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 15, 'criterion': 'entropy'}\n",
            "0.776 (+/-0.005) for {'n_estimators': 50, 'min_samples_split': 4, 'max_depth': 5, 'criterion': 'entropy'}\n",
            "0.774 (+/-0.003) for {'n_estimators': 500, 'min_samples_split': 9, 'max_depth': 5, 'criterion': 'entropy'}\n",
            "0.903 (+/-0.006) for {'n_estimators': 500, 'min_samples_split': 9, 'max_depth': 15, 'criterion': 'gini'}\n",
            "0.756 (+/-0.013) for {'n_estimators': 10, 'min_samples_split': 2, 'max_depth': 5, 'criterion': 'gini'}\n",
            "0.880 (+/-0.005) for {'n_estimators': 10, 'min_samples_split': 2, 'max_depth': 15, 'criterion': 'entropy'}\n",
            "0.899 (+/-0.007) for {'n_estimators': 50, 'min_samples_split': 9, 'max_depth': 15, 'criterion': 'entropy'}\n",
            "0.869 (+/-0.007) for {'n_estimators': 100, 'min_samples_split': 4, 'max_depth': 10, 'criterion': 'entropy'}\n",
            "0.767 (+/-0.017) for {'n_estimators': 10, 'min_samples_split': 4, 'max_depth': 5, 'criterion': 'entropy'}\n",
            "0.865 (+/-0.008) for {'n_estimators': 50, 'min_samples_split': 2, 'max_depth': 10, 'criterion': 'entropy'}\n",
            "0.869 (+/-0.006) for {'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 10, 'criterion': 'entropy'}\n",
            "0.903 (+/-0.006) for {'n_estimators': 300, 'min_samples_split': 4, 'max_depth': 15, 'criterion': 'entropy'}\n",
            "0.903 (+/-0.006) for {'n_estimators': 500, 'min_samples_split': 4, 'max_depth': 15, 'criterion': 'entropy'}\n",
            "0.776 (+/-0.007) for {'n_estimators': 500, 'min_samples_split': 4, 'max_depth': 5, 'criterion': 'entropy'}\n",
            "0.774 (+/-0.009) for {'n_estimators': 10, 'min_samples_split': 9, 'max_depth': 5, 'criterion': 'gini'}\n",
            "0.903 (+/-0.005) for {'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 15, 'criterion': 'gini'}\n",
            "0.903 (+/-0.008) for {'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 15, 'criterion': 'entropy'}\n",
            "0.867 (+/-0.009) for {'n_estimators': 50, 'min_samples_split': 4, 'max_depth': 10, 'criterion': 'entropy'}\n",
            "0.773 (+/-0.027) for {'n_estimators': 50, 'min_samples_split': 2, 'max_depth': 5, 'criterion': 'entropy'}\n",
            "0.870 (+/-0.005) for {'n_estimators': 300, 'min_samples_split': 9, 'max_depth': 10, 'criterion': 'entropy'}\n",
            "0.900 (+/-0.007) for {'n_estimators': 100, 'min_samples_split': 4, 'max_depth': 15, 'criterion': 'gini'}\n",
            "0.870 (+/-0.005) for {'n_estimators': 500, 'min_samples_split': 9, 'max_depth': 10, 'criterion': 'entropy'}\n",
            "0.900 (+/-0.007) for {'n_estimators': 50, 'min_samples_split': 4, 'max_depth': 15, 'criterion': 'entropy'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "\n",
            "# Tuning hyper-parameters for ********* recall\n",
            "\n",
            "Best parameters set found on development set:\n",
            "\n",
            "{'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 15, 'criterion': 'entropy'}\n",
            "\n",
            "Grid scores on development set:\n",
            "\n",
            "0.704 (+/-0.013) for {'n_estimators': 50, 'min_samples_split': 9, 'max_depth': 5, 'criterion': 'gini'}\n",
            "0.869 (+/-0.004) for {'n_estimators': 10, 'min_samples_split': 9, 'max_depth': 15, 'criterion': 'entropy'}\n",
            "0.703 (+/-0.006) for {'n_estimators': 300, 'min_samples_split': 4, 'max_depth': 5, 'criterion': 'gini'}\n",
            "0.885 (+/-0.008) for {'n_estimators': 100, 'min_samples_split': 9, 'max_depth': 15, 'criterion': 'gini'}\n",
            "0.843 (+/-0.008) for {'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 10, 'criterion': 'entropy'}\n",
            "0.704 (+/-0.006) for {'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 5, 'criterion': 'gini'}\n",
            "0.845 (+/-0.010) for {'n_estimators': 100, 'min_samples_split': 4, 'max_depth': 10, 'criterion': 'gini'}\n",
            "0.702 (+/-0.030) for {'n_estimators': 10, 'min_samples_split': 4, 'max_depth': 5, 'criterion': 'gini'}\n",
            "0.844 (+/-0.009) for {'n_estimators': 500, 'min_samples_split': 4, 'max_depth': 10, 'criterion': 'gini'}\n",
            "0.866 (+/-0.007) for {'n_estimators': 10, 'min_samples_split': 4, 'max_depth': 15, 'criterion': 'entropy'}\n",
            "0.703 (+/-0.005) for {'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 5, 'criterion': 'entropy'}\n",
            "0.888 (+/-0.008) for {'n_estimators': 500, 'min_samples_split': 4, 'max_depth': 15, 'criterion': 'entropy'}\n",
            "0.883 (+/-0.008) for {'n_estimators': 50, 'min_samples_split': 9, 'max_depth': 15, 'criterion': 'entropy'}\n",
            "0.887 (+/-0.008) for {'n_estimators': 300, 'min_samples_split': 4, 'max_depth': 15, 'criterion': 'gini'}\n",
            "0.704 (+/-0.007) for {'n_estimators': 500, 'min_samples_split': 4, 'max_depth': 5, 'criterion': 'gini'}\n",
            "0.882 (+/-0.008) for {'n_estimators': 50, 'min_samples_split': 2, 'max_depth': 15, 'criterion': 'gini'}\n",
            "0.825 (+/-0.011) for {'n_estimators': 10, 'min_samples_split': 2, 'max_depth': 10, 'criterion': 'entropy'}\n",
            "0.888 (+/-0.007) for {'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 15, 'criterion': 'entropy'}\n",
            "0.843 (+/-0.005) for {'n_estimators': 100, 'min_samples_split': 9, 'max_depth': 10, 'criterion': 'gini'}\n",
            "0.881 (+/-0.008) for {'n_estimators': 50, 'min_samples_split': 9, 'max_depth': 15, 'criterion': 'gini'}\n",
            "0.705 (+/-0.008) for {'n_estimators': 100, 'min_samples_split': 4, 'max_depth': 5, 'criterion': 'gini'}\n",
            "0.887 (+/-0.009) for {'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 15, 'criterion': 'gini'}\n",
            "0.699 (+/-0.014) for {'n_estimators': 10, 'min_samples_split': 2, 'max_depth': 5, 'criterion': 'entropy'}\n",
            "0.843 (+/-0.008) for {'n_estimators': 300, 'min_samples_split': 2, 'max_depth': 10, 'criterion': 'entropy'}\n",
            "0.701 (+/-0.009) for {'n_estimators': 500, 'min_samples_split': 9, 'max_depth': 5, 'criterion': 'entropy'}\n",
            "0.885 (+/-0.008) for {'n_estimators': 300, 'min_samples_split': 9, 'max_depth': 15, 'criterion': 'gini'}\n",
            "0.886 (+/-0.007) for {'n_estimators': 100, 'min_samples_split': 4, 'max_depth': 15, 'criterion': 'entropy'}\n",
            "0.705 (+/-0.006) for {'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 5, 'criterion': 'gini'}\n",
            "0.700 (+/-0.005) for {'n_estimators': 100, 'min_samples_split': 2, 'max_depth': 5, 'criterion': 'entropy'}\n",
            "0.843 (+/-0.008) for {'n_estimators': 50, 'min_samples_split': 4, 'max_depth': 10, 'criterion': 'gini'}\n",
            "\n",
            "Detailed classification report:\n",
            "\n",
            "The model is trained on the full development set.\n",
            "The scores are computed on the full evaluation set.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5h-Y6hGadZ9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d03dafa9-0302-4ee4-da3e-3b130bc39bc4"
      },
      "source": [
        "best_params = clf.best_params_\n",
        "print(best_params)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 15, 'criterion': 'entropy'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEf7e3wL7xG-"
      },
      "source": [
        "# print(\"Validating Accuracy\")\n",
        "# rf_Model_Scores = cross_val_score(**best_params, X, y, cv=5, scoring='accuracy')\n",
        "# rf_Model_Scores\n",
        "\n",
        "# precision\n",
        "# 'n_estimators': 500, 'min_samples_split': 4, 'max_depth': 15, 'criterion': 'entropy'\n",
        "# 'n_estimators': 300, 'min_samples_split': 4, 'max_depth': 15, 'criterion': 'entropy' # Home Precision\n",
        "# 'n_estimators': 500, 'min_samples_split': 2, 'max_depth': 15, 'criterion': 'entropy' # Home Recall"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7jRhw3gadc-"
      },
      "source": [
        "best_forest = RandomForestClassifier(**best_params)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH7OlCJFadfl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "13b54510-51da-435c-8a05-e2f70384a37b"
      },
      "source": [
        "%%time\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns \n",
        "\n",
        "print(\"Fitting our model to the train set\")\n",
        "fit_forest = best_forest.fit(X_train, y_train)\n",
        "print(\"Creating predicted variables to compare against y_test\")\n",
        "\n",
        "y_pred = fit_forest.predict(X_test)\n",
        "# making classification report and confusion matrix\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "ax= plt.subplot()\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, cmap=\"Blues\", annot=True, fmt='d', ) # for decimal\n",
        "\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['No ', 'Yes']); ax.yaxis.set_ticklabels(['No', 'Yes']);"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting our model to the train set\n",
            "Creating predicted variables to compare against y_test\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.95      0.92     28497\n",
            "           1       0.92      0.83      0.87     19021\n",
            "\n",
            "    accuracy                           0.90     47518\n",
            "   macro avg       0.91      0.89      0.90     47518\n",
            "weighted avg       0.90      0.90      0.90     47518\n",
            "\n",
            "CPU times: user 10min 2s, sys: 514 ms, total: 10min 2s\n",
            "Wall time: 10min\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEWCAYAAACHVDePAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5wV1f3/8dd7lyII0gTE3ojGEhVR7F/U2NJQo8ZO1K9orEnUaMpXE435aaLGaNQEIzbsLTYUsRCjsYCKCFggNkCQXgQEFj6/P+YsXnHL3XXvlnvfTx/z2HvPzJz5zLp87rlnzpxRRGBmZsWtrKkDMDOzwnOyNzMrAU72ZmYlwMnezKwEONmbmZUAJ3szsxLgZG9fm6R2kh6VNF/SfV+jnmMkPdWQsTUFSU9IGtjUcZjlcrIvIZKOljRa0meSpqWktEcDVH0Y0BPoFhGH17eSiLgjIvZvgHi+RFJ/SSHpodXKt0vlI/Os57eShta2XUQcFBG31jNcs4Jwsi8Rkn4OXA38gSwxbwhcDwxogOo3At6LiIoGqKtQZgK7SuqWUzYQeK+hDqCM/01Zs+Q/zBIgqRNwMXB6RDwYEYsiYnlEPBoR56Vt2kq6WtInablaUtu0rr+kKZLOkTQjfSs4Ia37HXAh8KP0jeGk1VvAkjZOLehW6f2PJb0vaaGkDyQdk1P+Qs5+u0kalbqHRknaLWfdSEmXSHox1fOUpLVr+DUsA/4JHJn2Lwd+BNyx2u/qL5ImS1og6TVJe6byA4Ff5ZznmzlxXCrpRWAxsGkq+9+0/gZJD+TUf7mkZyQp7/+BZg3Ayb407AqsATxUwza/BnYBtge2A3YGfpOzfh2gE7AecBJwnaQuEXER2beFeyKiQ0TcVFMgktYErgEOioiOwG7AmCq26wo8nrbtBlwFPL5ay/xo4ASgB9AGOLemYwO3Acen1wcA44BPVttmFNnvoCtwJ3CfpDUi4snVznO7nH2OAwYBHYGPVqvvHGDb9EG2J9nvbmB4nhJrZE72paEbMKuWbpZjgIsjYkZEzAR+R5bEKi1P65dHxDDgM2CLesazEthGUruImBYR46vY5rvAxIi4PSIqIuIu4B3g+znb3BwR70XEEuBesiRdrYj4D9BV0hZkSf+2KrYZGhGz0zGvBNpS+3neEhHj0z7LV6tvMdnv8SpgKHBmREyppT6zBudkXxpmA2tXdqNUY12+3Cr9KJWtqmO1D4vFQIe6BhIRi8i6T04Fpkl6XNKWecRTGdN6Oe+n1yOe24EzgL2p4puOpHMlvZ26juaRfZupqXsIYHJNKyPiFeB9QGQfSmaNzsm+NLwELAUOrmGbT8gutFbakK92ceRrEdA+5/06uSsjYnhE7Af0Imut35hHPJUxTa1nTJVuB04DhqVW9yqpm+UXwBFAl4joDMwnS9IA1XW91NglI+l0sm8In6T6zRqdk30JiIj5ZBdRr5N0sKT2klpLOkjSH9NmdwG/kdQ9Xei8kKzboT7GAHtJ2jBdHP5l5QpJPSUNSH33S8m6g1ZWUccw4BtpuGgrST8CtgIeq2dMAETEB8D/kF2jWF1HoIJs5E4rSRcCa+Ws/xTYuC4jbiR9A/g9cCxZd84vJNXY3WRWCE72JSL1P/+c7KLrTLKuhzPIRqhAlpBGA2OBt4DXU1l9jjUCuCfV9RpfTtBlKY5PgDlkifcnVdQxG/ge2QXO2WQt4u9FxKz6xLRa3S9ERFXfWoYDT5INx/wI+Jwvd9FU3jA2W9LrtR0ndZsNBS6PiDcjYiLZiJ7bK0c6mTUWeVCAmVnxc8vezKwEONmbmZUAJ3szsxLgZG9mVgJqusmmSbXb4QxfObavmDvqr00dgjVDa7Tia881VJecs+SNv7a4uY3csjczKwHNtmVvZtaoinx2aid7MzOAsvKmjqCgnOzNzACK/BEDTvZmZuBuHDOzkuCWvZlZCXDL3sysBLhlb2ZWAjwax8ysBLgbx8ysBLgbx8ysBLhlb2ZWApzszcxKQHlxX6At7o8yM7N8SfkvNVajDSQ9J2mCpPGSzk7lv5U0VdKYtHwnZ59fSpok6V1JB+SUH5jKJkm6IKd8E0mvpPJ7JLWp7fSc7M3MIOvGyXepWQVwTkRsBewCnC5pq7TuzxGxfVqGAaR1RwJbAwcC10sql1QOXAccBGwFHJVTz+Wprs2BucBJtQXlZG9mBg3Wso+IaRHxenq9EHgbWK+GXQYAd0fE0oj4AJgE7JyWSRHxfkQsA+4GBkgSsA9wf9r/VuDg2k7Pyd7MDOrUspc0SNLonGVQlVVKGwM7AK+kojMkjZU0RFKXVLYeMDlntymprLrybsC8iKhYrbxGTvZmZlCnln1EDI6IvjnL4K9Wpw7AA8BPI2IBcAOwGbA9MA24sjFPz6NxzMygQadLkNSaLNHfEREPAkTEpznrbwQeS2+nAhvk7L5+KqOa8tlAZ0mtUus+d/tquWVvZgYNdoE29anfBLwdEVfllPfK2ewQYFx6/QhwpKS2kjYBegOvAqOA3mnkTRuyi7iPREQAzwGHpf0HAg/Xdnpu2ZuZQUNOl7A7cBzwlqQxqexXZKNptgcC+BA4BSAixku6F5hANpLn9IhYkYWkM4DhQDkwJCLGp/rOB+6W9HvgDbIPlxo52ZuZQYPdQRsRLwBVfXIMq2GfS4FLqygfVtV+EfE+2WidvDnZm5mBp0swMysJns/ezKwEeIpjM7MS4G4cM7MS4Ja9mVnxk5O9mVnxc7I3MysBKnOyNzMrem7Zm5mVACd7M7MS4GRvZlYKijvXO9mbmYFb9mZmJaGszHfQmpkVPbfszcxKQXHneid7MzNwy97MrCQ42ZuZlQBPl2BmVgLcsjczKwFO9mZmJcDJ3sysBDjZm5mVguLO9U72Zmbg6RLMzEqCu3HMzEpBcef6wiZ7SesD1wJ7AAH8Gzg7IqYU8rjN0fo9O/OPS46nR7eORMCQB17kurtGcvtlJ9B7454AdO7YjnkLl7DLkZcBcO6J+/PjAbuyYuVKzvnj/Tz90tsAdOrQjhsuOpqtNutFBJz6uzt4ZewHdFmrPbdffiIbrduVjz6Zw7G/uIl5C5c02Tlb3V34m1/y/L9G0rVrNx58+LEvrbv1liFc9afLGfnCS3Tp0pXnnn2a6679C2Uqo7xVOeed/yv67NiXV195mSsu/3+r9vvgg/e5/Io/s8++327s02lR3LL/em4G7gQOT++PTWX7Ffi4zU7FipVccNWDjHlnCh3at+U/d57PM6+8w3EX3Lxqm8t+fgjzP8uS85abrsPhB/Shz2GX0qt7J4b97Qy2PfhiVq4MrvjFYTz1nwkcfd5NtG5VTvs12gBw7gn7MfLVd7ni5hGce8J+nHvC/vzmmoeb5HytfgYcfChHHX0sv/7l+V8qnz5tGi+9+CK9eq27qqxfv13pv/e+SOK9d9/hvHN+ysOPPcnO/Xbh3gez/+/z583jewftz6677d6o59ESFXuyL/QVie4RcXNEVKTlFqB7gY/ZLE2ftYAx72RfaD5bvJR3PpjOut07f2mbH+7Xh3uffA2A7/X/FvcNf51lyyv46JPZ/HfyLHbaZmPW6rAGe/TZjFseegmA5RUrVn1AfK//txj66CsADH30Fb6/97ca6/SsgezYdyfW6tTpK+V/uvz/8bNzzvtSQmq/5pqr3i9ZsqTKZDXiqeHsseeetGvXrnBBFwlJeS8tUaFb9rMlHQvcld4fBcwu8DGbvQ17dWX7LdZn1LgPV5Xt3mczPp2zkP9+PBOA9bp34pW3vlg/dcZc1u3RiSWfL2PW3M8Y/Ltj2fYb6/HG25M594/3s/jzZfTo1pHpsxYA2YdLj24dG/O0rECee/ZpevTswRZbbvmVdc88PYJrrr6SObPn8Ncb/v6V9U8+8TjHDTyhMcJs8Yp9bpxCt+xPBI4ApgPTgMOAav/yJA2SNFrS6IpZ4wscWtNYs10b7rrifznvigdYuOjzVeVHHNiX+54cXev+rVqVs/2WG3Djff9m16MuZ/GSpZx7YtW9YhENFrY1kSVLlvCPwX/ntDPOrnL9vt/ej4cfe5Krr72O6679y5fWzZw5g0kT32O33fdojFBbvGJv2Rc02UfERxHxg4joHhE9IuLgiPi4hu0HR0TfiOjbau2tCxlak2jVqoy7rjiZe54YzcPPvrmqvLy8jAH7bMf9w19fVTZ15nzWX6fLqvfr9ejCJzPmM/XTuUydMY9R4z4C4KGnx7D9lhsAMGP2QtZZey0A1ll7LWbOWdgYp2UFNGXyx0ydOoUjDh3AQfvtw6efTufIww5l1syZX9pux747MWXKZObOnbOq7Kknn2CfffejdevWjR12i+RkXw+SLqxh+b9CHLMl+NtFx/DuB9O5ZuizXyrfp98WvPfhp0ydMW9V2eMjx3L4AX1o07oVG63bjc037M6ocR/y6eyFTJk+l94b9QCg/85b8M7707N9/vUWx36/HwDHfr8fj40c20hnZoXS+xtbMPLfL/HEiGd5YsSz9Oy5Dnff/yBrd+/Oxx99RKSvb29PGM+yZcvo3PmLBsITwx7nwO98t6lCb3Gk/Jea69EGkp6TNEHSeElnp/KukkZImph+dknlknSNpEmSxkrqk1PXwLT9REkDc8p3lPRW2uca5fEJVKg++0VVlK0JnAR0Ay4p0HGbrd2235RjvtePt96byst3XwDARX99hOEvTODwA3ZcdWG20tvvT+eBp97gjQd+TcWKlfz0sntZuTL7h/3zy+/j5j/8mDatyvlw6iwGXTQUgCtuHsHQy09k4MG78vG0ORz7iyGNe5L2tZ1/7s8ZPepV5s2by3777MVPTj+TQ394eJXbPj1iOI8+8jCtW7Wi7Rpr8Mcr/ryq1Tl16hSmT59G3512bszwW7QGbLFXAOdExOuSOgKvSRoB/Bh4JiIuk3QBcAFwPnAQ0Dst/YAbgH6SugIXAX3Jhq6/JumRiJibtjkZeAUYBhwIPFHj+UWBO3bTyZ5NlujvBa6MiBm17dduhzPc42xfMXfUX5s6BGuG1mj19W+J2uL84XnnnHcvPyDv40l6GPhrWvpHxDRJvYCREbGFpL+n13el7d8F+lcuEXFKKv87MDItz0XElqn8qNztqlOwPvv0leX3wFiybxB9IuL8fBK9mVljq0s3Tu5gkrQMqrpObQzsQNYC7xkR09Kq6UDP9Ho9YHLOblNSWU3lU6oor1FBunEk/Qk4FBgMbBsRnxXiOGZmDaWsDkMvI2IwWX6rlqQOwAPATyNiQW43UUSEpEbtvShUy/4cYF3gN8AnkhakZaGkBQU6pplZvTXUBdqsLrUmS/R3RMSDqfjT1H1D+lnZyzEV2CBn9/VTWU3l61dRXqOCJPuIKIuIdhHRMSLWylk6RsRahTimmdnX0VBDL9PImJuAtyPiqpxVjwCVI2oGAg/nlB+fRuXsAsxP3T3Dgf0ldUkjd/YHhqd1CyTtko51fE5d1fKsl2Zm5Ndiz9PuwHHAW5LGpLJfAZcB90o6CfiI7IZTyEbTfAeYBCwm3XgaEXMkXQKMSttdHBGVN1KcBtwCtCMbhVPjSBxwsjczAxru4SUR8QLVT5i8bxXbB3B6NXUNAb4yhjoiRgPb1CUuJ3szMxq0Zd8sOdmbmVH8Uxw72ZuZ4Za9mVlJcMvezKwEFHmud7I3M4O63UHbEjnZm5nhbhwzs5JQ5Lneyd7MDNyyNzMrCUWe653szczAF2jNzEqCu3HMzEqAk72ZWQko8lzvZG9mBm7Zm5mVhCLP9U72Zmbg0ThmZiWhrMib9nV6Dld68O23ChWMmVlTkfJfWqJaW/aSRgI/SNu+BsyQ9GJE/LzAsZmZNZpiv0CbT8u+U0QsAA4FbouIfsC3CxuWmVnjKlP+S0uUT599K0m9gCOAXxc4HjOzJlHsF2jzadlfDAwHJkXEKEmbAhMLG5aZWeNSHf5riWpt2UfEfcB9Oe/fB35YyKDMzBpbkTfsq0/2kq4Forr1EXFWQSIyM2sCxX6BtqaW/ehGi8LMrIkVea6vPtlHxK257yW1j4jFhQ/JzKzxlfxNVZJ2lTQBeCe9307S9QWPzMysEZWVKe+lJcpnNM7VwAHAbICIeBPYq5BBmZk1tpK/gxYgIiavdvFiRWHCMTNrGsXejZNPsp8saTcgJLUGzgbeLmxYZmaNq7hTfX7J/lTgL8B6wCdkN1idXsigzMwaWykPvQQgImYBxzRCLGZmTaaFXnfNWz6jcTaV9KikmZJmSHo4TZlgZlY0PBoH7gTuBXoB65JNnXBXIYMyM2tskvJe8qhrSGocj8sp+62kqZLGpOU7Oet+KWmSpHclHZBTfmAqmyTpgpzyTSS9ksrvkdSmtpjySfbtI+L2iKhIy1BgjTz2MzNrMRp4iuNbgAOrKP9zRGyflmEAkrYCjgS2TvtcL6lcUjlwHXAQsBVwVNoW4PJU1+bAXOCkWs+vuhWSukrqCjwh6QJJG0vaSNIvgGF5na6ZWQvRkC37iHgemJPnoQcAd0fE0oj4AJgE7JyWSRHxfkQsA+4GBigLYB/g/rT/rcDBtR2kpgu0r5FNhFZ5ZqfkngvwyzxPxMys2atLT7ykQcCgnKLBETE4j13PkHQ82dxj50TEXLKRji/nbDMllQFMXq28H9ANmBcRFVVsX62a5sbZJI/AzcyKQnkdLrymxJ5Pcs91A3AJWWP5EuBK4MQ61lFved1BK2kbsj6jVX31EXFboYIyM2tshR5nHxGf5hzrRuCx9HYqsEHOpuunMqopnw10ltQqte5zt69WPkMvLwKuTcvewB/JHkBuZlY0Cj03Tnq8a6VDgMqROo8AR0pqK2kToDfwKjAK6J1G3rQhu4j7SEQE8BxwWNp/IPBwbcfPp2V/GLAd8EZEnCCpJzA0j/3MzFqMhpwbR9JdQH9gbUlTgIuA/pK2J+vG+ZB0HTQixku6F5gAVACnR8SKVM8ZZLMWlANDImJ8OsT5wN2Sfg+8AdxUW0z5JPslEbFSUoWktYAZfPmrhZlZi9eQvTgRcVQVxdUm5Ii4FLi0ivJhVDH6MT0edue6xJRPsh8tqTNwI9kInc+Al+pykPr4+PmrC30Ia4EG3vFGU4dgzdA9A3f42nV4bpyI09LLv0l6ElgrIsYWNiwzs8ZVXqrJXlKfmtZFxOuFCcnMrPG10Clv8lZTy/7KGtYF2R1cZmZFoWSTfUTs3ZiBmJk1pZLvszczKwUl27I3MyslRd6wd7I3MwNoVeTZPp/pEiTpWEkXpvcbSqrTYH4zs+au0NMlNLV8Hl5yPbArUHlH2EKyCfXNzIpGmZT30hLl043TLyL6SHoDICLm5vMILDOzlqSF5vC85ZPsl6fHYwWApO7AyoJGZWbWyDwaB64BHgJ6SLqUbBbM3xQ0KjOzRlaXh5e0RPnMjXOHpNeAfcme3HVwRLxd8MjMzBpRkef62pO9pA2BxcCjuWUR8XEhAzMza0yq01NoW558unEe54sHj68BbAK8C2xdwLjMzBpVybfsI2Lb3PdpNszTqtnczKxFKvlkv7qIeF1Sv0IEY2bWVEp+IjRJP895Wwb0AT4pWERmZk2gPJ9bTFuwfFr2HXNeV5D14T9QmHDMzJpGS70zNl81Jvt0M1XHiDi3keIxM2sSJdtnL6lVRFRI2r0xAzIzawpF3rCvsWX/Kln//BhJjwD3AYsqV0bEgwWOzcys0ZR5nD1rALPJnjlbOd4+ACd7Mysapdyy75FG4ozjiyRfKQoalZlZI2tV5J32NSX7cqADVPndxsnezIpKKbfsp0XExY0WiZlZEyrloZfFfeZmZjmKPNfXmOz3bbQozMyaWJHfQFt9so+IOY0ZiJlZUyrlbhwzs5LhZG9mVgKKO9U72ZuZAcV/gbbYr0mYmeVFUt5LHnUNkTRD0ricsq6SRkiamH52SeWSdI2kSZLGpgdEVe4zMG0/UdLAnPIdJb2V9rlGeQTlZG9mRpYM813ycAtw4GplFwDPRERv4Jn0HuAgoHdaBgE3QPbhAFwE9AN2Bi6q/IBI25ycs9/qx6ry/MzMSl6ZlPdSm4h4Hlh9ROMA4Nb0+lbg4Jzy2yLzMtBZUi/gAGBERMyJiLnACODAtG6tiHg5IgK4Laeu6s+v9l+BmVnxq0s3jqRBkkbnLIPyOETPiJiWXk8HeqbX6wGTc7abkspqKp9SRXmNfIHWzIy6tXwjYjAwuL7HioiQ1KhzjLllb2ZGw16grcanqQuG9HNGKp8KbJCz3fqprKby9asor5GTvZkZ2Tj7fJd6egSoHFEzEHg4p/z4NCpnF2B+6u4ZDuwvqUu6MLs/MDytWyBplzQK5/icuqrlbhwzM6C8AQfaS7oL6A+sLWkK2aiay4B7JZ0EfAQckTYfBnwHmAQsBk6AbMoaSZcAo9J2F+dMY3Ma2YifdsATaamRk72ZGQ17U1VEHFXNqq9MMJlG1JxeTT1DgCFVlI8GtqlLTE72ZmaAinzCBCd7MzOKf7oEJ3szM6DMLXszs+Lnlr2ZWQnwfPZmZiWgrLhzfeFuqpK0maS26XV/SWdJ6lyo45mZfR2qw38tUSHvoH0AWCFpc7I5JDYA7izg8czM6k3Kf2mJCtmNszIiKiQdAlwbEddKeqOAx2sxli5dyhknH8+y5ctYsWIFe++7PyedcgYP3HMH9951O1OnTOaxp1+gc+ds6urXR7/KL885k17rZRPb/c/e3+aEk0+rth5rOU7dbUP6rL8WCz6v4NxH3gHgsO3WYd9vdGPB5xUA3PX6NMZMXUC54JTdNmSTbu0pl3j+v3P457hPAWjfupxTdtuADbq0g4Ab/vMRE2cuZqMu7Th51w1oXS5WrISbXpnMf2ctbrLzbc5aaos9X4VM9sslHUU2B8T3U1nrAh6vxWjTpg1/+dsQ2rdfk4qK5fzkpOPot9uebLtdH3bbsz9nnvLjr+yz3Q478serr8+rnm223a6RzsS+rn/9dzbD35nJ6Xts9KXyxyfM5LHxM75UtsvGXWhdXsZ5j7xDm3Jx5cHf5MUP5jJz0TJ+vPN6vPnJQv78rw8pLxNty7Mv7cf0XZf735zOmKkL2H69tThmx3W5ePikRju/lsR99vV3ArArcGlEfCBpE+D2Ah6vxZBE+/ZrAlBRUcGKigok8Y0tv0mvdWudlrrWeqzlePvTRXy2dEVe2wbQtlUZZYI2rcqoWBEsXr6Cdq3L+GbPDjw7cTYAK1Zm5ZU7tWud/TNv36acuYuXF+I0ikJDPrykOSpYyz4iJkg6H9gwvf8AuLxQx2tpVqxYwUnHHc7UyR9zyOFHsfU236px+3FvjWHgUYewdvcenH72eWy62eb1qsdahgO2XJu9Nu3K+7MXc/voqSxatoJXPpzLTht04u9HbEOb8jJuG5WVb9SlHQuWVvCT3Tdkoy7t+GD2Ym4ZNZWlFSu5ddQUfvXtzTm273qUCf5v2HtNfWrNVstM4fkr5Gic7wNjgCfT++0lPVLLPque/nLbzTcWKrRmoby8nFvufJAHhz3L2+Pf4v1JE6vddostt+L+R0dw610PcdgRx/Crc8+sVz3WMox4dxZnPTiB8x99h7lLlnNc3+zb3uZrr8nKCE69dxxnPjiB723dgx4d2lBeBpt0bc+Id2dxwWPv8nnFSgZskz0Eab8t1ubWUVM4/f7x3PrqVE7dbaOaDl3Sir1lX8hunN+SPSR3HkBEjAE2rWmHiBgcEX0jou/xJ5xcwNCaj44d16JP3515+aUXqt1mzQ4dVnXX7LrHXlRUVDBv3tw612Mtw/zPK4jIum2efW82m6/dHoDdN+3CmKkLWBGw4PMK3p2xiE27tWf2ouXMXryMSenC6ysfzWOTbu0A+J/NuvHqx/MBePmjeWyW6rKvaoT57JtUIZP98oiYv1rZygIer8WYO3cOCxcuAGDp558z6pWX2GjjTardfvasmWSzoMKEcWNZuXIlnTp1rnM91jJ0bvdF7+pOG3Vi8rzPAZi1aBnb9OoIZH33vbu355MFnzP/8wpmL1pOr7XaArBNr45MSfvMXbycrXp2yMrX6cD0hUsb81RaliLP9g3eZy9pGNnczOMlHQ2US+oNnAX8p6GP1xLNnjWTSy/6FStXrmTlypXss98B7L5nf+67eyh33jaEObNnMfDIQ9h197244P8uZuQzT/HQA/dQXl5O27Zr8Ls/XIGkauuxluOsvTZmq54d6LhGK64/bGvuGzONrdbpyMZd2xEBMxct48aXPgZg+DuzOG33DbliwJYIGDlpDh/PzZL6za9M4cw9N6ZVmZjx2VJueDHb5+8vfcyPd16fcollK1Yy+D8fN9WpNnsttXsmX6psMTZYhdLhwKVkI2/aAfulVcOBSyIir6bFzIUVjfowXmsZznjwraYOwZqhewbu8LUz9aj35+edc3batFOL+2Ro8G6ciLgP6AN0AL4L3APcDcylmqexmJk1OXfj1MsyYBHQlizpu5VuZs2a76CtI0kHAleRPTG9T0T43mwza/aKvMu+IC37XwOHR8T4AtRtZlYQRZ7rGz7ZR8SeDV2nmVmhFftUI354iZkZ7sYxMysJRZ7rnezNzICiz/ZO9mZmeOilmVlJcJ+9mVkJcLI3MysB7sYxMysBbtmbmZWAIs/1TvZmZkDRZ3snezMziv/hJYV8LKGZWYvRkNPZS/pQ0luSxkgancq6ShohaWL62SWVS9I1kiZJGiupT049A9P2EyUN/Drn52RvZgaFeHjJ3hGxfUT0Te8vAJ6JiN7AM+k9wEFA77QMAm6A7MMBuAjoB+wMXFT5AVEfTvZmZmRDL/P9r54GALem17cCB+eU3xaZl4HOknoBBwAjImJORMwFRgAH1vfgTvZmZmRDL/Nd8hDAU5JekzQolfWMiGnp9XSgZ3q9HjA5Z98pqay68nrxBVozM+o2GCcl8EE5RYMjYnDO+z0iYqqkHsAISe/k7h8RIalRH9fqZG9mRt0eXpIS++Aa1k9NP2dIeoisz/1TSb0iYlrqppmRNp8KbJCz+/qpbCrQf7XykXkHuRp345iZ0XDdOJLWlNSx8jWwPzCO7LnclSNqBgIPp9ePAMenUTm7APNTd89wYH9JXdKF2f1TWb24ZW9mRoPeU9UTeCh9U2gF3NuOE2UAAAZcSURBVBkRT0oaBdwr6STgI+CItP0w4DvAJGAxcAJARMyRdAkwKm13cUTMqW9QTvZmZtBg2T4i3ge2q6J8NrBvFeUBnF5NXUOAIQ0Rl5O9mRme9dLMrCQU+WwJTvZmZgBlTvZmZqWguLO9k72ZGe7GMTMrCUWe653szczALXszs5JQl+kSWiInezMz3I1jZlYSirxh72RvZga+g9bMrDQUd653sjczg6LP9U72ZmYAZUXeae9kb2ZG8V+g9ZOqzMxKgFv2ZmYUf8veyd7MDA+9NDMrCW7Zm5mVACd7M7MS4G4cM7MS4Ja9mVkJKPJc72RvZgYUfbZ3sjczo/inS1BENHUMVgtJgyJicFPHYc2L/y6sLjxdQsswqKkDsGbJfxeWNyd7M7MS4GRvZlYCnOxbBvfLWlX8d2F58wVaM7MS4Ja9mVkJcLI3MysBTvbNhKSQdGXO+3Ml/bYJQ7ImpswLkg7KKTtc0pNNGZe1TE72zcdS4FBJazd1INY8RHZB7VTgKklrSOoA/AE4vWkjs5bIyb75qCAbXfGz1VdI2ljSs5LGSnpG0oaNH541hYgYBzwKnA9cCAwFfi3pVUlvSBoAIGnrVDYm/Z30bsKwrRnyaJxmQtJnwLrAWGA74GSgQ0T8VtKjwP0RcaukE4EfRMTBTRiuNSJJawKvA8uAx4DxETFUUmfgVWAH4DLg5Yi4Q1IboDwiljRZ0NbsONk3E5I+i4gOki4GlgNL+CLZzwJ6RcRySa2BaRHh7p4Skv4uPgOOANYg+yYI0BU4gCzh/xq4DXgwIiY2RZzWfLkbp/m5GjgJWLOpA7FmZWVaBPwwIrZPy4YR8XZE3An8gKyRMEzSPk0ZrDU/TvbNTETMAe4lS/iV/gMcmV4fA/y7seOyZmM4cKaUzccraYf0c1Pg/Yi4BngY+FbThWjNkZN983QlkNtNcyZwgqSxwHHA2U0SlTUHlwCtgbGSxqf3kHXvjJM0BtiGrDvHbBX32ZuZlQC37M3MSoCTvZlZCXCyNzMrAU72ZmYlwMnezKwEONnbV0hakeZYGSfpPkntv0Zdt0g6LL3+h6Stati2v6Td6nGMD6uaQK668tW2+ayOx/qtpHPrGqNZU3Oyt6osSXdnbkM2H8upuSsltapPpRHxvxExoYZN+gN1TvZmVjsne6vNv4HNU6v735IeASZIKpf0J0mj0iyLp8CqOdj/KuldSU8DPSorkjRSUt/0+kBJr0t6M83kuTHZh8rP0reKPSV1l/RAOsYoSbunfbtJekrSeEn/IJtCoEaS/inptbTPoNXW/TmVPyOpeyrbTNKTaZ9/S9qyijrPkjQhnf/d9fv1mjWOerXQrDSkFvxBQOXDMvoA20TEBylhzo+InSS1BV6U9BTZhFxbAFsBPYEJwJDV6u0O3AjslerqGhFzJP0N+Cwirkjb3Qn8OSJeSNM6Dwe+CVwEvBARF0v6Ll+eWqI6J6ZjtANGSXogImaTzUE0OiJ+JunCVPcZZNNNnxoREyX1A64HVp9v5gJgk4hYmmagNGu2nOytKu3SbfeQtexvIuteeTUiPkjl+wPfquyPBzoBvYG9gLsiYgXwiaRnq6h/F+D5yrrSfEBV+TawVZoGBmCt9ACPvYBD076PS5qbxzmdJemQ9HqDFOtsssnF7knlQ4EH0zF2A+7LOXbbKuocC9wh6Z/AP/OIwazJONlbVZZExPa5BSnpLcotAs6MiOGrbfedBoyjDNglIj6vIpa8SepP9sGxa0QsljSSbJrgqkQ67rzVfwdV+C7ZB8/3yR4osm1EVNSyj1mTcJ+91ddw4Cdpfn0kfSM9ZON54EepT78XsHcV+74M7CVpk7Rv11S+EOiYs91TZJPAkbarTL7PA0ensoOALrXE2gmYmxL9lmTfLCqVAZXfTo4m6x5aAHwg6fB0DEnaLrdCSWXABhHxHNlTpDoBHWqJw6zJONlbff2DrD/+dUnjgL+TfVN8CJiY1t0GvLT6jhExExhE1mXyJl90ozwKHFJ5gRY4C+ibLoBO4ItRQb8j+7AYT9ad83EtsT4JtJL0NumJTjnrFgE7p3PYB7g4lR8DnJTiGw8MWK3OcmCopLeAN4BrImJeLXGYNRnPemlmVgLcsjczKwFO9mZmJcDJ3sysBDjZm5mVACd7M7MS4GRvZlYCnOzNzErA/webucm9FTBgIwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsF4hLlONUtT"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwDNlDVWHYAn"
      },
      "source": [
        "# SGD\n",
        "from sklearn.linear_model import SGDClassifier"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE-8mjQGL5te",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d1f66430-ea4c-42a3-f85b-a4be6f5b6070"
      },
      "source": [
        "result = []\n",
        "for m in ['log', 'hinge','modified_huber', 'squared_hinge', 'perceptron']:\n",
        "    clf.loss = m\n",
        "    print(clf)\n",
        "    for i in [1E-2, 1E-1, 1e0, 1e1, 1e2, 1e3]: # Full List\n",
        "    # for i in [1E-1, 1e0]:\n",
        "#         print(i)\n",
        "#         clf.alpha = i\n",
        "        clf = SGDClassifier(loss=m, alpha=i, penalty=\"l2\", max_iter=1000)\n",
        "        print(clf)\n",
        "        print(\"Fitting\")\n",
        "        clf_Fit = clf.fit(X_train, y_train)\n",
        "        print(\"Scoring\")\n",
        "        clf_Score = clf.score(X_test, y_test)\n",
        "#         print(clf_Score)\n",
        "#         print(\"Predicting\")\n",
        "#         clf_preds = clf.predict(X_test)\n",
        "        print(m, i, clf_Score)\n",
        "        print(\"Appending to Dict\")\n",
        "        result.append({\n",
        "            \"Loss\": m,\n",
        "            'Alpha': i,\n",
        "            'Model_Fit': clf,\n",
        "            'Score': clf_Score,\n",
        "#             'Preds': clf_preds,\n",
        "            })\n",
        "\n",
        "result = pd.DataFrame(result)\n",
        "resultDF = result.sort_values(by='Score', ascending=False)\n",
        "display(resultDF)  \n",
        "# result.to_csv(r'result.csv')\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=30,\n",
            "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
            "                                        'max_depth': [5, 10, 15],\n",
            "                                        'min_samples_split': [2, 4, 9],\n",
            "                                        'n_estimators': [10, 50, 100, 300,\n",
            "                                                         500]},\n",
            "                   scoring='recall_macro')\n",
            "SGDClassifier(alpha=0.01, loss='log')\n",
            "Fitting\n",
            "Scoring\n",
            "log 0.01 0.685992676459447\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=0.1, loss='log')\n",
            "Fitting\n",
            "Scoring\n",
            "log 0.1 0.7015657224630666\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=1.0, loss='log')\n",
            "Fitting\n",
            "Scoring\n",
            "log 1.0 0.7005766235952692\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=10.0, loss='log')\n",
            "Fitting\n",
            "Scoring\n",
            "log 10.0 0.6474809545856307\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=100.0, loss='log')\n",
            "Fitting\n",
            "Scoring\n",
            "log 100.0 0.6862452123405868\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=1000.0, loss='log')\n",
            "Fitting\n",
            "Scoring\n",
            "log 1000.0 0.6293404604570899\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=1000.0)\n",
            "SGDClassifier(alpha=0.01)\n",
            "Fitting\n",
            "Scoring\n",
            "hinge 0.01 0.706932109937287\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=0.1)\n",
            "Fitting\n",
            "Scoring\n",
            "hinge 0.1 0.7011237846710721\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=1.0)\n",
            "Fitting\n",
            "Scoring\n",
            "hinge 1.0 0.7026389999579107\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=10.0)\n",
            "Fitting\n",
            "Scoring\n",
            "hinge 10.0 0.6568458268445642\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=100.0)\n",
            "Fitting\n",
            "Scoring\n",
            "hinge 100.0 0.6890231070331243\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=1000.0)\n",
            "Fitting\n",
            "Scoring\n",
            "hinge 1000.0 0.5490761395681636\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=1000.0, loss='modified_huber')\n",
            "SGDClassifier(alpha=0.01, loss='modified_huber')\n",
            "Fitting\n",
            "Scoring\n",
            "modified_huber 0.01 0.7003240877141294\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=0.1, loss='modified_huber')\n",
            "Fitting\n",
            "Scoring\n",
            "modified_huber 0.1 0.6976724609621617\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=1.0, loss='modified_huber')\n",
            "Fitting\n",
            "Scoring\n",
            "modified_huber 1.0 0.69573635254009\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=10.0, loss='modified_huber')\n",
            "Fitting\n",
            "Scoring\n",
            "modified_huber 10.0 0.6609284902563239\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=100.0, loss='modified_huber')\n",
            "Fitting\n",
            "Scoring\n",
            "modified_huber 100.0 0.5211498800454565\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=1000.0, loss='modified_huber')\n",
            "Fitting\n",
            "Scoring\n",
            "modified_huber 1000.0 0.6225219916663159\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=1000.0, loss='squared_hinge')\n",
            "SGDClassifier(alpha=0.01, loss='squared_hinge')\n",
            "Fitting\n",
            "Scoring\n",
            "squared_hinge 0.01 0.6723767835346606\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=0.1, loss='squared_hinge')\n",
            "Fitting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scoring\n",
            "squared_hinge 0.1 0.5873774148743633\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=1.0, loss='squared_hinge')\n",
            "Fitting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scoring\n",
            "squared_hinge 1.0 0.6081905804116335\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=10.0, loss='squared_hinge')\n",
            "Fitting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scoring\n",
            "squared_hinge 10.0 0.6023401658318953\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=100.0, loss='squared_hinge')\n",
            "Fitting\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scoring\n",
            "squared_hinge 100.0 0.5977945199713792\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=1000.0, loss='squared_hinge')\n",
            "Fitting\n",
            "Scoring\n",
            "squared_hinge 1000.0 0.620059766825203\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=1000.0, loss='perceptron')\n",
            "SGDClassifier(alpha=0.01, loss='perceptron')\n",
            "Fitting\n",
            "Scoring\n",
            "perceptron 0.01 0.6284355402163391\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=0.1, loss='perceptron')\n",
            "Fitting\n",
            "Scoring\n",
            "perceptron 0.1 0.6019824066669472\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=1.0, loss='perceptron')\n",
            "Fitting\n",
            "Scoring\n",
            "perceptron 1.0 0.6047182120459615\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=10.0, loss='perceptron')\n",
            "Fitting\n",
            "Scoring\n",
            "perceptron 10.0 0.6480070710046719\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=100.0, loss='perceptron')\n",
            "Fitting\n",
            "Scoring\n",
            "perceptron 100.0 0.4916452712656257\n",
            "Appending to Dict\n",
            "SGDClassifier(alpha=1000.0, loss='perceptron')\n",
            "Fitting\n",
            "Scoring\n",
            "perceptron 1000.0 0.4528810135106696\n",
            "Appending to Dict\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Loss</th>\n",
              "      <th>Alpha</th>\n",
              "      <th>Model_Fit</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>hinge</td>\n",
              "      <td>0.01</td>\n",
              "      <td>SGDClassifier(alpha=0.01)</td>\n",
              "      <td>0.706932</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>hinge</td>\n",
              "      <td>1.00</td>\n",
              "      <td>SGDClassifier(alpha=1.0)</td>\n",
              "      <td>0.702639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>log</td>\n",
              "      <td>0.10</td>\n",
              "      <td>SGDClassifier(alpha=0.1, loss='log')</td>\n",
              "      <td>0.701566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>hinge</td>\n",
              "      <td>0.10</td>\n",
              "      <td>SGDClassifier(alpha=0.1)</td>\n",
              "      <td>0.701124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>log</td>\n",
              "      <td>1.00</td>\n",
              "      <td>SGDClassifier(alpha=1.0, loss='log')</td>\n",
              "      <td>0.700577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>modified_huber</td>\n",
              "      <td>0.01</td>\n",
              "      <td>SGDClassifier(alpha=0.01, loss='modified_huber')</td>\n",
              "      <td>0.700324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>modified_huber</td>\n",
              "      <td>0.10</td>\n",
              "      <td>SGDClassifier(alpha=0.1, loss='modified_huber')</td>\n",
              "      <td>0.697672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>modified_huber</td>\n",
              "      <td>1.00</td>\n",
              "      <td>SGDClassifier(alpha=1.0, loss='modified_huber')</td>\n",
              "      <td>0.695736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>hinge</td>\n",
              "      <td>100.00</td>\n",
              "      <td>SGDClassifier(alpha=100.0)</td>\n",
              "      <td>0.689023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>log</td>\n",
              "      <td>100.00</td>\n",
              "      <td>SGDClassifier(alpha=100.0, loss='log')</td>\n",
              "      <td>0.686245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>log</td>\n",
              "      <td>0.01</td>\n",
              "      <td>SGDClassifier(alpha=0.01, loss='log')</td>\n",
              "      <td>0.685993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>squared_hinge</td>\n",
              "      <td>0.01</td>\n",
              "      <td>SGDClassifier(alpha=0.01, loss='squared_hinge')</td>\n",
              "      <td>0.672377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>modified_huber</td>\n",
              "      <td>10.00</td>\n",
              "      <td>SGDClassifier(alpha=10.0, loss='modified_huber')</td>\n",
              "      <td>0.660928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>hinge</td>\n",
              "      <td>10.00</td>\n",
              "      <td>SGDClassifier(alpha=10.0)</td>\n",
              "      <td>0.656846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>perceptron</td>\n",
              "      <td>10.00</td>\n",
              "      <td>SGDClassifier(alpha=10.0, loss='perceptron')</td>\n",
              "      <td>0.648007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>log</td>\n",
              "      <td>10.00</td>\n",
              "      <td>SGDClassifier(alpha=10.0, loss='log')</td>\n",
              "      <td>0.647481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>log</td>\n",
              "      <td>1000.00</td>\n",
              "      <td>SGDClassifier(alpha=1000.0)</td>\n",
              "      <td>0.629340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>perceptron</td>\n",
              "      <td>0.01</td>\n",
              "      <td>SGDClassifier(alpha=0.01, loss='perceptron')</td>\n",
              "      <td>0.628436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>modified_huber</td>\n",
              "      <td>1000.00</td>\n",
              "      <td>SGDClassifier(alpha=1000.0, loss='squared_hinge')</td>\n",
              "      <td>0.622522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>squared_hinge</td>\n",
              "      <td>1000.00</td>\n",
              "      <td>SGDClassifier(alpha=1000.0, loss='perceptron')</td>\n",
              "      <td>0.620060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>squared_hinge</td>\n",
              "      <td>1.00</td>\n",
              "      <td>SGDClassifier(alpha=1.0, loss='squared_hinge')</td>\n",
              "      <td>0.608191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>perceptron</td>\n",
              "      <td>1.00</td>\n",
              "      <td>SGDClassifier(alpha=1.0, loss='perceptron')</td>\n",
              "      <td>0.604718</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>squared_hinge</td>\n",
              "      <td>10.00</td>\n",
              "      <td>SGDClassifier(alpha=10.0, loss='squared_hinge')</td>\n",
              "      <td>0.602340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>perceptron</td>\n",
              "      <td>0.10</td>\n",
              "      <td>SGDClassifier(alpha=0.1, loss='perceptron')</td>\n",
              "      <td>0.601982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>squared_hinge</td>\n",
              "      <td>100.00</td>\n",
              "      <td>SGDClassifier(alpha=100.0, loss='squared_hinge')</td>\n",
              "      <td>0.597795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>squared_hinge</td>\n",
              "      <td>0.10</td>\n",
              "      <td>SGDClassifier(alpha=0.1, loss='squared_hinge')</td>\n",
              "      <td>0.587377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>hinge</td>\n",
              "      <td>1000.00</td>\n",
              "      <td>SGDClassifier(alpha=1000.0, loss='modified_hub...</td>\n",
              "      <td>0.549076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>modified_huber</td>\n",
              "      <td>100.00</td>\n",
              "      <td>SGDClassifier(alpha=100.0, loss='modified_huber')</td>\n",
              "      <td>0.521150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>perceptron</td>\n",
              "      <td>100.00</td>\n",
              "      <td>SGDClassifier(alpha=100.0, loss='perceptron')</td>\n",
              "      <td>0.491645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>perceptron</td>\n",
              "      <td>1000.00</td>\n",
              "      <td>SGDClassifier(alpha=1000.0, loss='perceptron')</td>\n",
              "      <td>0.452881</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Loss  ...     Score\n",
              "6            hinge  ...  0.706932\n",
              "8            hinge  ...  0.702639\n",
              "1              log  ...  0.701566\n",
              "7            hinge  ...  0.701124\n",
              "2              log  ...  0.700577\n",
              "12  modified_huber  ...  0.700324\n",
              "13  modified_huber  ...  0.697672\n",
              "14  modified_huber  ...  0.695736\n",
              "10           hinge  ...  0.689023\n",
              "4              log  ...  0.686245\n",
              "0              log  ...  0.685993\n",
              "18   squared_hinge  ...  0.672377\n",
              "15  modified_huber  ...  0.660928\n",
              "9            hinge  ...  0.656846\n",
              "27      perceptron  ...  0.648007\n",
              "3              log  ...  0.647481\n",
              "5              log  ...  0.629340\n",
              "24      perceptron  ...  0.628436\n",
              "17  modified_huber  ...  0.622522\n",
              "23   squared_hinge  ...  0.620060\n",
              "20   squared_hinge  ...  0.608191\n",
              "26      perceptron  ...  0.604718\n",
              "21   squared_hinge  ...  0.602340\n",
              "25      perceptron  ...  0.601982\n",
              "22   squared_hinge  ...  0.597795\n",
              "19   squared_hinge  ...  0.587377\n",
              "11           hinge  ...  0.549076\n",
              "16  modified_huber  ...  0.521150\n",
              "28      perceptron  ...  0.491645\n",
              "29      perceptron  ...  0.452881\n",
              "\n",
              "[30 rows x 4 columns]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEvAXtMoMCBu"
      },
      "source": [
        "# XGD Boost\n",
        "import xgboost as xgb"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzdbiN50MSon"
      },
      "source": [
        "dtrain = xgb.DMatrix(X_train,label=y_train)\n",
        "dtest = xgb.DMatrix(X_test,label=y_test)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6XMgt4SMUo0"
      },
      "source": [
        "evallist = [(dtest, 'eval'), (dtrain, 'train')]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X5nO49yMU4_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3453c8d-c4f5-48a0-dbf8-619d2cf7f216"
      },
      "source": [
        "num_round = 100 # Test\n",
        "param = {\n",
        "    'max_depth': 10,\n",
        "    'objective': 'multi:softmax',\n",
        "    'num_class': 10,\n",
        "    'eta': 0.3    }\n",
        "param"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eta': 0.3, 'max_depth': 10, 'num_class': 10, 'objective': 'multi:softmax'}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25Ep_0saMWHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c435912-d122-4b13-c934-3b37736b6144"
      },
      "source": [
        "my_model = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\teval-merror:0.145587\ttrain-merror:0.124231\n",
            "Multiple eval metrics have been passed: 'train-merror' will be used for early stopping.\n",
            "\n",
            "Will train until train-merror hasn't improved in 5 rounds.\n",
            "[1]\teval-merror:0.133802\ttrain-merror:0.110657\n",
            "[2]\teval-merror:0.122038\ttrain-merror:0.096308\n",
            "[3]\teval-merror:0.112715\ttrain-merror:0.085629\n",
            "[4]\teval-merror:0.106591\ttrain-merror:0.07946\n",
            "[5]\teval-merror:0.102782\ttrain-merror:0.074192\n",
            "[6]\teval-merror:0.099478\ttrain-merror:0.069935\n",
            "[7]\teval-merror:0.09649\ttrain-merror:0.066057\n",
            "[8]\teval-merror:0.092554\ttrain-merror:0.061322\n",
            "[9]\teval-merror:0.091586\ttrain-merror:0.058787\n",
            "[10]\teval-merror:0.089271\ttrain-merror:0.056424\n",
            "[11]\teval-merror:0.087925\ttrain-merror:0.054404\n",
            "[12]\teval-merror:0.086683\ttrain-merror:0.052997\n",
            "[13]\teval-merror:0.086052\ttrain-merror:0.051861\n",
            "[14]\teval-merror:0.085462\ttrain-merror:0.050336\n",
            "[15]\teval-merror:0.084389\ttrain-merror:0.049471\n",
            "[16]\teval-merror:0.083379\ttrain-merror:0.048469\n",
            "[17]\teval-merror:0.082663\ttrain-merror:0.046999\n",
            "[18]\teval-merror:0.082453\ttrain-merror:0.046224\n",
            "[19]\teval-merror:0.080748\ttrain-merror:0.043852\n",
            "[20]\teval-merror:0.07957\ttrain-merror:0.041732\n",
            "[21]\teval-merror:0.079107\ttrain-merror:0.041155\n",
            "[22]\teval-merror:0.078981\ttrain-merror:0.04019\n",
            "[23]\teval-merror:0.078454\ttrain-merror:0.038909\n",
            "[24]\teval-merror:0.078602\ttrain-merror:0.036717\n",
            "[25]\teval-merror:0.078286\ttrain-merror:0.035536\n",
            "[26]\teval-merror:0.078181\ttrain-merror:0.034895\n",
            "[27]\teval-merror:0.077718\ttrain-merror:0.034129\n",
            "[28]\teval-merror:0.077297\ttrain-merror:0.032911\n",
            "[29]\teval-merror:0.076266\ttrain-merror:0.031802\n",
            "[30]\teval-merror:0.076539\ttrain-merror:0.031044\n",
            "[31]\teval-merror:0.076582\ttrain-merror:0.030738\n",
            "[32]\teval-merror:0.076392\ttrain-merror:0.030386\n",
            "[33]\teval-merror:0.076308\ttrain-merror:0.03016\n",
            "[34]\teval-merror:0.07614\ttrain-merror:0.029673\n",
            "[35]\teval-merror:0.076329\ttrain-merror:0.029159\n",
            "[36]\teval-merror:0.076182\ttrain-merror:0.028835\n",
            "[37]\teval-merror:0.076224\ttrain-merror:0.027527\n",
            "[38]\teval-merror:0.076224\ttrain-merror:0.02694\n",
            "[39]\teval-merror:0.07635\ttrain-merror:0.024668\n",
            "[40]\teval-merror:0.076308\ttrain-merror:0.024496\n",
            "[41]\teval-merror:0.076645\ttrain-merror:0.023558\n",
            "[42]\teval-merror:0.075445\ttrain-merror:0.022115\n",
            "[43]\teval-merror:0.075403\ttrain-merror:0.021231\n",
            "[44]\teval-merror:0.075108\ttrain-merror:0.020672\n",
            "[45]\teval-merror:0.074919\ttrain-merror:0.02005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44GpRdlHMhPw"
      },
      "source": [
        "print(my_model.best_iteration)\n",
        "print(my_model.best_score)\n",
        "# eta .01 = 0.069\n",
        "# eta .03 = 0.001416\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yStwbK-UMhfs"
      },
      "source": [
        "out = xgb.cv(params=param, \n",
        "             dtrain=dtrain, \n",
        "             num_boost_round=3500, \n",
        "             nfold=3, \n",
        "             verbose_eval=True, \n",
        "             early_stopping_rounds=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2a9kVB1MlfJ"
      },
      "source": [
        "out.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8Ro2FG1Mlr2"
      },
      "source": [
        "out.iloc[-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMX7pTjeMm6G"
      },
      "source": [
        "out.sort_values(by='test-merror-mean', ascending=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIm8fEi-MoKw"
      },
      "source": [
        "my_model.predict(dtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAT0-387MqfU"
      },
      "source": [
        "plt.plot(out['train-merror-mean'], label='Train Data')\n",
        "plt.plot(out['test-merror-mean'], label='Test Data')\n",
        "plt.ylabel('Score') \n",
        "plt.xlabel('Number of Boost Iterations') \n",
        "plt.title(\"Score and Boost Iterations\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMK6uuJ-Mr6E"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "XGBoost_AC = accuracy_score(my_model.predict(dtest), y_test)\n",
        "print(\"The Best XG Boost Accuracy Score is:\", XGBoost_AC)\n",
        "# .01 eta - 0.9311208384191254\n",
        "# .03 eta - 0.931499642240835"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9g0kNJvMuzO"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(20, 20))\n",
        "xgb.plot_tree(my_model, num_trees=10, ax=ax)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xqyf-tRCMvA_"
      },
      "source": [
        "# NN\n",
        "import tensorflow as tf\n",
        "# y_test\n",
        "# y_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15xzvG6oL4gl"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model_Classify = tf.keras.Sequential()\n",
        "model_Classify.add(tf.keras.Input(shape=(45,)))\n",
        "model_Classify.add(tf.keras.layers.Dense(500, activation='sigmoid', kernel_initializer='zeros'))  # adds a layer with 500 neurons, sigmoid activation\n",
        "model_Classify.add(tf.keras.layers.Dense(250, activation='sigmoid'))   # adds a layer with 250` neurons, sigmoid activation\n",
        "model_Classify.add(tf.keras.layers.Dense(100, activation='sigmoid'))   # adds a layer with 100 neurons, sigmoid activation\n",
        "model_Classify.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # adds a layer with 1 neurons, sigmoid\n",
        "\n",
        "model_Classify.compile(optimizer='sgd',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1ITAkp1L6WA"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\n",
        "\n",
        "model_Classify.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=25, batch_size=25, callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29he-gcTDlwN"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model_Classify2 = tf.keras.Sequential()\n",
        "model_Classify2.add(tf.keras.Input(shape=(45,)))\n",
        "model_Classify2.add(tf.keras.layers.Dense(500, activation='sigmoid', kernel_initializer='zeros'))  # adds a layer with 500 neurons, sigmoid activation\n",
        "model_Classify2.add(tf.keras.layers.Dense(250, activation='sigmoid'))   # adds a layer with 250` neurons, sigmoid activation\n",
        "model_Classify2.add(tf.keras.layers.Dense(100, activation='sigmoid'))   # adds a layer with 100 neurons, sigmoid activation\n",
        "model_Classify2.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # adds a layer with 1 neurons, sigmoid\n",
        "\n",
        "model_Classify2.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              # loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTX9FeWCDtc3"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1)\n",
        "\n",
        "model_Classify2.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=25, batch_size=25, callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwkQK_voupen"
      },
      "source": [
        "model_Classify2_preds = model_Classify2.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V_Bn3XxvUO6"
      },
      "source": [
        "# making classification report and confusion matrix\n",
        "model_Classify2_preds = (model_Classify2_preds > 0.5).astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBkLnasir053"
      },
      "source": [
        "model_Classify2_preds_DF = pd.DataFrame(model_Classify2_preds)\n",
        "print(model_Classify2_preds_DF.shape)\n",
        "print(len(X_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s17vj5BWWzm7"
      },
      "source": [
        "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "ax= plt.subplot()\n",
        "cm = confusion_matrix(y_test, model_Classify2_preds_DF)\n",
        "sns.heatmap(cm, cmap=\"Blues\", annot=True, fmt='d', ) # for decimal\n",
        "\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['No', 'Yes']); ax.yaxis.set_ticklabels(['No', 'Yes']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyZBk9u5hZeJ"
      },
      "source": [
        "sns.heatmap(cm, cmap=\"Blues\", annot=True, fmt='d', ) # for decimal\n",
        "\n",
        "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['No', 'Yes']); ax.yaxis.set_ticklabels(['No', 'Yes']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBwnmgBBhZiM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3IdtnzeWzve"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAK7SHJISY9n"
      },
      "source": [
        "### Cost Loss / Win "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6IDyweo9zbd"
      },
      "source": [
        "# Accuracy times Shape\n",
        "# True Postive\n",
        "# False Postive\n",
        "# Need to Reveiw The LEcture before you write it up\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCEmpxRO90I3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}